#!/usr/bin/env python3
"""
DART MCP Server - Open DART APIë¥¼ MCP ë„êµ¬ë¡œ ì œê³µí•˜ëŠ” ì„œë²„
"""

import asyncio
import json
import logging
import os
import sys
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import requests
import pandas as pd
import zipfile
import io
import re
import xml.etree.ElementTree as ET

# PDF íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬(ì„ íƒ)
try:
    import pdfplumber
    PDF_AVAILABLE = True
except Exception:
    PDF_AVAILABLE = False

# AWS Secrets Manager (ì„ íƒ)
try:
    import boto3
    from botocore.exceptions import ClientError
    BOTO_AVAILABLE = True
except Exception:
    BOTO_AVAILABLE = False

from mcp.server import Server, NotificationOptions
from mcp.server.models import InitializationOptions
from mcp.server.stdio import stdio_server
from mcp.types import Tool
import mcp.types as types

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from cache_manager import cache_manager, cached_api_call
from news_analyzer import news_analyzer
from report_generator import report_generator
from portfolio_analyzer import portfolio_analyzer
from time_series_analyzer import time_series_analyzer
from benchmark_analyzer import benchmark_analyzer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("dart-mcp-server")

# ì „ì—­ ë³€ìˆ˜
API_KEY = None
CORP_CODE_CACHE = {}
# Perplexity API í‚¤ë„ í•¨ê»˜ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ì „ì—­ì— ë³´ê´€
PERPLEXITY_API_KEY = None

# ì£¼ìš” ê¸°ì—… ë§¤í•‘ í…Œì´ë¸” (ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´)
MAJOR_COMPANIES = {
    'ì‚¼ì„±ì „ì': 'ì‚¼ì„±ì „ìì£¼ì‹íšŒì‚¬',
    'í˜„ëŒ€ìë™ì°¨': 'í˜„ëŒ€ìë™ì°¨ì£¼ì‹íšŒì‚¬', 
    'SKí•˜ì´ë‹‰ìŠ¤': 'SKí•˜ì´ë‹‰ìŠ¤ì£¼ì‹íšŒì‚¬',
    'LGì „ì': 'LGì „ìì£¼ì‹íšŒì‚¬',
    'NAVER': 'ë„¤ì´ë²„ì£¼ì‹íšŒì‚¬',
    'ì¹´ì¹´ì˜¤': 'ì£¼ì‹íšŒì‚¬ì¹´ì¹´ì˜¤',
    'í¬ìŠ¤ì½”': 'í¬ìŠ¤ì½”í™€ë”©ìŠ¤ì£¼ì‹íšŒì‚¬',
    'ì‚¼ì„±SDI': 'ì‚¼ì„±SDIì£¼ì‹íšŒì‚¬',
    'LGí™”í•™': 'LGí™”í•™ì£¼ì‹íšŒì‚¬',
    'í˜„ëŒ€ëª¨ë¹„ìŠ¤': 'í˜„ëŒ€ëª¨ë¹„ìŠ¤ì£¼ì‹íšŒì‚¬',
    'KBê¸ˆìœµ': 'KBê¸ˆìœµì§€ì£¼ì£¼ì‹íšŒì‚¬',
    'ì‹ í•œì§€ì£¼': 'ì‹ í•œì§€ì£¼ì£¼ì‹íšŒì‚¬',
    'SK': 'SKì£¼ì‹íšŒì‚¬',
    'LG': 'LGì£¼ì‹íšŒì‚¬'
}

# AWS Secrets Managerì—ì„œë§Œ API í‚¤ ë¡œë“œ
try:
    if BOTO_AVAILABLE:
        try:
            region_name = os.getenv("AWS_REGION", "ap-northeast-2")
            session = boto3.session.Session()
            client = session.client(service_name='secretsmanager', region_name=region_name)

            # 1) í†µí•© ì‹œí¬ë¦¿(JSON) ìš°ì„ : OPENCORPINSIGHT_SECRETS { DART_API_KEY, PERPLEXITY_API_KEY }
            for secret_name in ["OPENCORPINSIGHT_SECRETS", "DART_API_KEY", "PERPLEXITY_API_KEY"]:
                try:
                    resp = client.get_secret_value(SecretId=secret_name)
                except ClientError:
                    continue
                secret_string = resp.get('SecretString')
                if not secret_string:
                    continue
                s = secret_string.strip()
                if s.startswith('{'):
                    import json as _json
                    data = _json.loads(s)
                    API_KEY = API_KEY or data.get('DART_API_KEY') or data.get('dart_api_key')
                    PERPLEXITY_API_KEY = PERPLEXITY_API_KEY or data.get('PERPLEXITY_API_KEY') or data.get('perplexity_api_key')
                else:
                    if secret_name == "DART_API_KEY" and not API_KEY:
                        API_KEY = s
                    if secret_name == "PERPLEXITY_API_KEY" and not PERPLEXITY_API_KEY:
                        PERPLEXITY_API_KEY = s
            if API_KEY:
                logger.info("DART API í‚¤ë¥¼ AWS Secrets Managerì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤")
            if PERPLEXITY_API_KEY:
                logger.info("PERPLEXITY_API_KEYë¥¼ AWS Secrets Managerì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.warning(f"Secrets Manager ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {e}")
    if not API_KEY:
        logger.error("DART API í‚¤ ë¡œë“œ ì‹¤íŒ¨: AWS Secrets Managerì— í‚¤ë¥¼ ì €ì¥í•´ ì£¼ì„¸ìš”")
    if not PERPLEXITY_API_KEY:
        logger.warning("PERPLEXITY_API_KEY ë¯¸ì„¤ì •: ë‰´ìŠ¤ ê´€ë ¨ ë„êµ¬ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
except Exception as e:
    logger.warning(f"ì´ˆê¸°í™” ì¤‘ ì˜ˆì™¸: {e}")

# MCP ì„œë²„ ìƒì„± ë° ì´ˆê¸°í™”
app = Server("OpenCorpInsight")

# Perplexity MCP ê²€ìƒ‰ í•¨ìˆ˜ (ì‹¤ì œ API í˜¸ì¶œ)
async def perplexity_search_wrapper(query: str, recency_filter: Optional[str] = None):
    """Perplexity APIë¥¼ í†µí•´ JSON ë‰´ìŠ¤ ëª©ë¡ì„ ë°›ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë°˜í™˜ í˜•ì‹: {"articles": [{"title":...,"content":...,"url":...,"source":...,"published_date":"YYYY-MM-DD"}, ...]}
    """
    try:
        if not PERPLEXITY_API_KEY:
            logger.warning("PERPLEXITY_API_KEY ë¯¸ì„¤ì • - Mockìœ¼ë¡œ ëŒ€ì²´ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            return {"articles": []}
        period_map = {'day': 'ì§€ë‚œ 24ì‹œê°„', 'week': 'ì§€ë‚œ 7ì¼', 'month': 'ì§€ë‚œ 30ì¼'}
        period_text = period_map.get(recency_filter or '', 'ìµœê·¼')

        api_url = "https://api.perplexity.ai/chat/completions"
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "X-API-Key": PERPLEXITY_API_KEY,
            "Content-Type": "application/json"
        }
        prompt = (
            "ì•„ë˜ ì§ˆì˜ì— ëŒ€í•´ í•œêµ­ì–´ ë‰´ìŠ¤ 10ê±´ì„ JSON ê°ì²´ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”. í‚¤ëŠ” 'articles'ì´ë©°, ê° í•­ëª©ì€ "
            "{title, content, url, source, published_date(YYYY-MM-DD)} í•„ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì¶”ê°€ ì„¤ëª…/ì„œë¬¸ ê¸ˆì§€.\n"
            f"ì§ˆì˜: {query} ê´€ë ¨ {period_text} ìµœì‹  ë‰´ìŠ¤"
        )
        body = {
            "model": "sonar-small-online",
            "messages": [
                {"role": "system", "content": "ë„ˆëŠ” ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°ì´ë‹¤. ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•œë‹¤."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 800,
            "temperature": 0.2,
            "response_format": {"type": "json_object"}
        }
        resp = requests.post(api_url, headers=headers, json=body, timeout=30)
        if resp.status_code != 200:
            logger.warning(f"Perplexity API í˜¸ì¶œ ì‹¤íŒ¨: {resp.status_code} {resp.text[:200]}")
            return {"articles": []}
        data = resp.json()
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "{}")
        try:
            parsed = json.loads(content)
            if isinstance(parsed, dict) and 'articles' in parsed:
                return parsed
        except Exception:
            pass
        return {"articles": []}
    except Exception as e:
        logger.error(f"Perplexity ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {"articles": []}

# ë‰´ìŠ¤ ë¶„ì„ê¸°ì— Perplexity ê²€ìƒ‰ í•¨ìˆ˜ ì—°ê²° (Secrets í‚¤ í•„ìš”)
try:
    if PERPLEXITY_API_KEY:
        news_analyzer.set_perplexity_search_function(perplexity_search_wrapper)
        logger.info("ë‰´ìŠ¤ ë¶„ì„ê¸°ì— Perplexity ê²€ìƒ‰ í•¨ìˆ˜ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        logger.warning("PERPLEXITY_API_KEY ë¯¸ì„¤ì • - ë‰´ìŠ¤ ë„êµ¬ ë¹„í™œì„±í™”")
except Exception:
    logger.warning("Perplexity ê²€ìƒ‰ í•¨ìˆ˜ ì—°ê²° ì‹¤íŒ¨")

async def get_corp_code(corp_name: str) -> str:
    """ê¸°ì—… ê³ ìœ ë²ˆí˜¸ ì¡°íšŒ"""
    # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
    logger.info(f"get_corp_code í˜¸ì¶œë¨ - corp_name: {corp_name}")
    logger.info(f"í˜„ì¬ API_KEY ìƒíƒœ: {API_KEY[:10] if API_KEY else 'None'}...")
    logger.info(f"API_KEY íƒ€ì…: {type(API_KEY)}")
    
    if not API_KEY:
        raise ValueError("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    if corp_name in CORP_CODE_CACHE:
        return CORP_CODE_CACHE[corp_name]
    
    # ì£¼ìš” ê¸°ì—… ë§¤í•‘ í™•ì¸
    search_name = MAJOR_COMPANIES.get(corp_name, corp_name)
    if search_name != corp_name:
        logger.info(f"ì£¼ìš” ê¸°ì—… ë§¤í•‘ ì‚¬ìš©: {corp_name} -> {search_name}")
        # ë§¤í•‘ëœ ì´ë¦„ë„ ìºì‹œì—ì„œ í™•ì¸
        if search_name in CORP_CODE_CACHE:
            CORP_CODE_CACHE[corp_name] = CORP_CODE_CACHE[search_name]
            return CORP_CODE_CACHE[search_name]
    
    # corpCode API í˜¸ì¶œ
    zip_url = f'https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={API_KEY}'
    resp = requests.get(zip_url, timeout=20)
    if resp.status_code != 200:
        raise ValueError(f"ê³ ìœ ë²ˆí˜¸ ëª©ë¡ ìš”ì²­ ì‹¤íŒ¨: HTTP {resp.status_code}")
    zip_bytes = resp.content

    bio = io.BytesIO(zip_bytes)
    if not zipfile.is_zipfile(bio):
        # DARTê°€ ì˜¤ë¥˜ JSON/ë¬¸ìì—´ì„ ë°˜í™˜í–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë©”ì‹œì§€ ì¶”ì¶œ ì‹œë„
        try:
            j = resp.json(); status = j.get('status'); msg = j.get('message')
            raise ValueError(f"ê³ ìœ ë²ˆí˜¸ ì¡°íšŒ ì˜¤ë¥˜: {status} {msg}")
        except Exception:
            text_snippet = zip_bytes[:200].decode('utf-8', errors='ignore')
            raise ValueError(f"ê³ ìœ ë²ˆí˜¸ ZIP ì•„ë‹˜ ì‘ë‹µ: {text_snippet}")
    bio.seek(0)
    with zipfile.ZipFile(bio) as zf:
        corp_bytes = zf.read('CORPCODE.xml')
        try:
            xml_str = corp_bytes.decode('euc-kr')
        except UnicodeDecodeError:
            xml_str = corp_bytes.decode('utf-8')
    
    root = ET.fromstring(xml_str)
    
    # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•œ í›„ë³´ ëª©ë¡ (ìƒì¥ì‚¬ë§Œ í—ˆìš©)
    exact_matches = []
    partial_matches = []
    
    for item in root.findall('.//list'):
        name = item.find('corp_name').text
        code = item.find('corp_code').text
        stock_code = (item.find('stock_code').text or '').strip()
        if not stock_code:
            continue  # ë¹„ìƒì¥(E ë“±) ì œì™¸
        
        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„  (ì›ë˜ ì´ë¦„ê³¼ ë§¤í•‘ëœ ì´ë¦„ ëª¨ë‘ í™•ì¸)
        if (name == corp_name or name == search_name or 
            name == corp_name + "ì£¼ì‹íšŒì‚¬" or name == "ì£¼ì‹íšŒì‚¬" + corp_name or
            name == search_name + "ì£¼ì‹íšŒì‚¬" or name == "ì£¼ì‹íšŒì‚¬" + search_name):
            exact_matches.append((name, code))
        # ë¶€ë¶„ ë§¤ì¹­ (ì›ë˜ ì´ë¦„ê³¼ ë§¤í•‘ëœ ì´ë¦„ ëª¨ë‘ í™•ì¸)
        elif corp_name in name or search_name in name:
            partial_matches.append((name, code))
    
    # ì •í™•í•œ ë§¤ì¹­ì´ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
    if exact_matches:
        # ê°€ì¥ ì§§ì€ ì´ë¦„ ì„ íƒ (ë³¸ì‚¬ ìš°ì„ )
        best_match = min(exact_matches, key=lambda x: len(x[0]))
        CORP_CODE_CACHE[corp_name] = best_match[1]
        logger.info(f"ì •í™•í•œ ë§¤ì¹­(ìƒì¥ì‚¬) ë°œê²¬: {corp_name} -> {best_match[0]} ({best_match[1]})")
        return best_match[1]
    
    # ë¶€ë¶„ ë§¤ì¹­ì—ì„œ ê°€ì¥ ì í•©í•œ ê²ƒ ì„ íƒ
    if partial_matches:
        # íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²ƒ ì œì™¸ (ì„œë¹„ìŠ¤, ì¨ë¹„ìŠ¤, ìíšŒì‚¬ ë“±)
        filtered_matches = []
        exclude_keywords = ['ì„œë¹„ìŠ¤', 'ì¨ë¹„ìŠ¤', 'ì¼€ì´', 'CS', 'ì”¨ì—ìŠ¤', 'ì—ìŠ¤']
        
        for name, code in partial_matches:
            if not any(keyword in name for keyword in exclude_keywords):
                filtered_matches.append((name, code))
        
        if filtered_matches:
            # ê°€ì¥ ì§§ì€ ì´ë¦„ ì„ íƒ (ë³¸ì‚¬ ìš°ì„ )
            best_match = min(filtered_matches, key=lambda x: len(x[0]))
            CORP_CODE_CACHE[corp_name] = best_match[1]
            logger.info(f"í•„í„°ë§ëœ ë§¤ì¹­(ìƒì¥ì‚¬) ë°œê²¬: {corp_name} -> {best_match[0]} ({best_match[1]})")
            return best_match[1]
        else:
            # í•„í„°ë§ í›„ì—ë„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì‹¤íŒ¨ ì²˜ë¦¬(ë¹„ìƒì¥ ì œì™¸ ì •ì±…)
            raise ValueError(f"ìƒì¥ ê¸°ì—… '{corp_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ìƒì¥ì‚¬ ëª…ì¹­/í‹°ì»¤ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.")
    
    raise ValueError(f"ê¸°ì—… '{corp_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# API í‚¤ ì„¤ì • í•¨ìˆ˜
async def set_dart_api_key(api_key: str) -> List[types.TextContent]:
    """DART API í‚¤ ì„¤ì •"""
    global API_KEY
    API_KEY = api_key
    logger.info(f"API í‚¤ ì„¤ì •ë¨: {API_KEY[:10]}...")
    return [types.TextContent(type="text", text=f"âœ… DART API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {api_key[:10]}...")]

# corp_code í•´ì„ ìœ í‹¸: í”„ë¡ íŠ¸ê°€ corp_codeë¥¼ ì§ì ‘ ë„˜ê¸°ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
def resolve_corp_code_arg(corp_name: Optional[str] = None, corp_code: Optional[str] = None) -> str:
    if corp_code:
        return corp_code
    if not corp_name:
        raise ValueError("corp_code ë˜ëŠ” corp_name ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤.")
    return asyncio.get_event_loop().run_until_complete(get_corp_code(corp_name))

# ê¸°ì—… ì •ë³´ ì¡°íšŒ
async def get_company_info(corp_name: Optional[str] = None, corp_code: Optional[str] = None) -> List[types.TextContent]:
    """ê¸°ì—… ì •ë³´ ì¡°íšŒ (corp_code ìš°ì„ )"""
    try:
        corp_code = corp_code or (await get_corp_code(corp_name))
        
        url = 'https://opendart.fss.or.kr/api/company.json'
        params = {
            'crtfc_key': API_KEY,
            'corp_code': corp_code
        }
        
        response = requests.get(url, params=params)
        data = response.json()
        
        if data['status'] != '000':
            return [types.TextContent(type="text", text=f"ì˜¤ë¥˜: {data['message']}")]
        
        info = data
        display_name = corp_name or info.get('corp_name', 'N/A')
        result = f"""
## {display_name} ê¸°ì—… ì •ë³´

- **íšŒì‚¬ëª…**: {info.get('corp_name', 'N/A')}
- **ëŒ€í‘œìëª…**: {info.get('ceo_nm', 'N/A')}
- **ì„¤ë¦½ì¼**: {info.get('est_dt', 'N/A')}
- **ì£¼ì†Œ**: {info.get('adres', 'N/A')}
- **í™ˆí˜ì´ì§€**: {info.get('hm_url', 'N/A')}
- **ì—…ì¢…**: {info.get('bizr_no', 'N/A')}
"""
        
        return [types.TextContent(type="text", text=result)]
        
    except Exception as e:
        return [types.TextContent(type="text", text=f"ê¸°ì—… ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¬ë¬´ì œí‘œ ì¡°íšŒ
async def get_financial_statements(corp_name: Optional[str], bsns_year: str, reprt_code: str, fs_div: str, statement_type: str, corp_code: Optional[str] = None) -> List[types.TextContent]:
    """ì¬ë¬´ì œí‘œ ì¡°íšŒ (corp_code ìš°ì„ )"""
    try:
        corp_code = corp_code or (await get_corp_code(corp_name))
        # corp_nameì´ ì—†ìœ¼ë©´ íšŒì‚¬ëª… ë³´ê°•
        display_name = corp_name
        if not display_name:
            try:
                info = requests.get('https://opendart.fss.or.kr/api/company.json', params={'crtfc_key': API_KEY, 'corp_code': corp_code}).json()
                if info.get('status') == '000':
                    display_name = info.get('corp_name')
            except Exception:
                pass
        logger.info(f"ì¬ë¬´ì œí‘œ ì¡°íšŒ ì‹œì‘: {display_name or corp_code} ({corp_code}) - {bsns_year}ë…„ {statement_type}")

        # ê³µì‹œê²€ìƒ‰ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ê²°ì •: pblntf_ty A(ì •ê¸°/ì‚¬ì—…ë³´ê³ ì„œ ìš°ì„ ) â†’ F(ê°ì‚¬ë³´ê³ ì„œ)
        def _prefer_report_code(corp_code: str, year: str) -> Optional[tuple[str, str]]:
            try:
                base_params = {
                    'crtfc_key': API_KEY,
                    'corp_code': corp_code,
                    'bgn_de': f"{year}0101",
                    'end_de': f"{year}1231",
                    'page_count': 100
                }
                # 1) A ìš°ì„ 
                params_a = dict(base_params); params_a['pblntf_ty'] = 'A'
                res_a = requests.get('https://opendart.fss.or.kr/api/list.json', params=params_a).json()
                if res_a.get('status') == '000' and any('ì‚¬ì—…ë³´ê³ ì„œ' in (it.get('report_nm','')) for it in (res_a.get('list') or [])):
                    return ('11014', 'A')
                # 2) F (ê°ì‚¬ë³´ê³ ì„œ)
                params_f = dict(base_params); params_f['pblntf_ty'] = 'F'
                res_f = requests.get('https://opendart.fss.or.kr/api/list.json', params=params_f).json()
                if res_f.get('status') == '000' and any('ê°ì‚¬ë³´ê³ ì„œ' in (it.get('report_nm','')) for it in (res_f.get('list') or [])):
                    return ('11014', 'F')  # ì—°ê°„ ê¸°ì¤€ìœ¼ë¡œ 11014 ìš°ì„  ì‹œë„
            except Exception:
                pass
            return None

        pref = _prefer_report_code(corp_code, bsns_year)
        preferred_code, preferred_source = (pref[0], pref[1]) if pref else (None, None)

        # ìš”ì²­ëœ ë³´ê³ ì„œ ì½”ë“œ
        requested_code = reprt_code

        # ê³µì‹œ ìš°ì„  íƒì§€ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
        # - ì—°ê°„(11014) ìš”ì²­ì´ë©´ ì‹¤íŒ¨ ì¦‰ì‹œ ë°˜í™˜(ì´ì „ ì •ì±… ìœ ì§€)
        # - ë¶„ê¸°/ë°˜ê¸°(11013/11012/11011) ìš”ì²­ì´ë©´ íƒì§€ ì—†ì–´ë„ ì§„í–‰ í—ˆìš©
        if not preferred_code and requested_code == '11014':
            msg = f"## {display_name or corp_code} {bsns_year}ë…„ ì¬ë¬´ì œí‘œ ì¡°íšŒ ì‹¤íŒ¨\n\nâŒ **ë°ì´í„° ì—†ìŒ**: ì •ê¸°(A)Â·ê°ì‚¬(F) ê³µì‹œì—ì„œ í•´ë‹¹ ì—°ë„ ë³´ê³ ì„œê°€ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\nğŸ” ê³µì‹œ ìš°ì„  íƒì§€: ì—†ìŒ\n"
            return [types.TextContent(type="text", text=msg)]

        # ë³´ê³ ì„œ ì½”ë“œ ëª©ë¡ êµ¬ì„±
        def unique(seq: List[str]) -> List[str]:
            seen = set(); out = []
            for x in seq:
                if x not in seen and x is not None:
                    seen.add(x); out.append(x)
            return out
        if requested_code in ['11013','11012','11011']:
            # ë¶„ê¸°/ë°˜ê¸° ìš”ì²­: ìš”ì²­ ì½”ë“œ ìš°ì„ , ê·¸ ì™¸ ë¶„ê¸° ì½”ë“œë¥¼ ë³´ì¡° ìˆœì„œë¡œ ì‹œë„
            quarterly_order = ['11013','11012','11011']
            report_codes = [requested_code] + [c for c in quarterly_order if c != requested_code]
        else:
            # ì—°ê°„ ìš”ì²­: ìš°ì„  íƒì§€ ì½”ë“œ(ìˆìœ¼ë©´) â†’ 11014ë§Œ ì‹œë„
            report_codes = ['11014'] if requested_code == '11014' else unique([requested_code, preferred_code])
        fs_divisions = unique([fs_div, 'CFS', 'OFS'])

        best_result = None
        attempted_combinations: List[str] = []

        for rcode in report_codes:
            for fsdiv in fs_divisions:
                try:
                    url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
                    params = {
                        'crtfc_key': API_KEY,
                        'corp_code': corp_code,
                        'bsns_year': bsns_year,
                        'reprt_code': rcode,
                        'fs_div': fsdiv
                    }

                    combo = f"{rcode}-{fsdiv}"
                    attempted_combinations.append(combo)
                    logger.info(f"ì‹œë„ ì¤‘: {rcode} ({_get_report_name(rcode)}) - {fsdiv}")

                    response = requests.get(url, params=params)
                    data = response.json()

                    if data.get('status') == '000' and 'list' in data:
                        df = pd.DataFrame(data['list'])
                        if df.empty:
                            continue
                        # ìš”ì²­í•œ ì¬ë¬´ì œí‘œ íƒ€ì… ì°¾ê¸°
                        statement_df = df[df['sj_nm'] == statement_type].copy()

                        if not statement_df.empty:
                            amount_cols = [c for c in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount'] if c in statement_df.columns]
                            if amount_cols:
                                result_df = statement_df[['account_nm', *amount_cols]].rename(columns={
                                    'account_nm': 'ê³„ì •',
                                    'thstrm_amount': 'ë‹¹ê¸°',
                                    'frmtrm_amount': 'ì „ê¸°',
                                    'bfefrmtrm_amount': 'ì „ì „ê¸°'
                                })
                                report_name = _get_report_name(rcode)
                                fs_name = "ì—°ê²°" if fsdiv == "CFS" else "ë³„ë„"
                                prefer_text = f" (ê³µì‹œê¸°ë°˜ ìš°ì„ : {'ì •ê¸°(A)' if preferred_source=='A' else 'ê°ì‚¬(F)'} ê°ì§€)" if preferred_source else ""
                                result = f"""
## {display_name or corp_code} {bsns_year}ë…„ {statement_type} ({report_name}, {fs_name}){prefer_text}

{result_df.to_string(index=False)}

ğŸ“Š **ë°ì´í„° ì •ë³´**
- ë³´ê³ ì„œ: {report_name} ({rcode})
- ì¬ë¬´ì œí‘œ: {fs_name} ({fsdiv})
- í•­ëª© ìˆ˜: {len(result_df)}ê°œ
"""
                                logger.info(f"ì¬ë¬´ì œí‘œ ì¡°íšŒ ì„±ê³µ: {rcode}-{fsdiv}, {len(result_df)}ê°œ í•­ëª©")
                                return [types.TextContent(type="text", text=result)]
                        else:
                            # í‘œì¤€ APIì—ì„œ ë¹„ì–´ìˆìœ¼ë©´ XBRL ë°±ì—… ì‹œë„ (ëª¨ë“  ì¬ë¬´ì œí‘œ ìœ í˜•)
                            xbrl_info = _detect_report_rcept_no(corp_code, bsns_year)
                            if xbrl_info:
                                rcept_no, src = xbrl_info
                                xdf = _try_fetch_statement_from_xbrl(rcept_no, statement_type)
                                if xdf is not None and not xdf.empty:
                                    report_name = 'ì‚¬ì—…/ê°ì‚¬(XBRL)'
                                    fs_name = 'ì—°ê²°/ë³„ë„ ì‹ë³„ë¶ˆê°€'
                                    prefer_text = f" (ê³µì‹œê¸°ë°˜ ìš°ì„ : {'ì •ê¸°(A)' if src=='A' else 'ê°ì‚¬(F)'} ê°ì§€)"
                                    result = f"""
## {display_name or corp_code} {bsns_year}ë…„ {statement_type} ({report_name}, {fs_name}){prefer_text}

{xdf.to_string(index=False)}

ğŸ“Š **ë°ì´í„° ì •ë³´**
- ì†ŒìŠ¤: XBRL íŒŒì‹± (rcept_no={rcept_no})
- í•­ëª© ìˆ˜: {len(xdf)}ê°œ
"""
                                    return [types.TextContent(type="text", text=result)]

                        # ë‹¤ë¥¸ ì¬ë¬´ì œí‘œ íƒ€ì…ë“¤ë„ í™•ì¸
                        available_statements = df['sj_nm'].unique().tolist()
                        if available_statements and not best_result:
                            best_result = {
                                'corp_name': display_name or corp_code,
                                'year': bsns_year,
                                'report_code': rcode,
                                'fs_div': fsdiv,
                                'available_statements': available_statements,
                                'total_records': len(df)
                            }

                except Exception as e:
                    logger.warning(f"ì¡°íšŒ ì‹¤íŒ¨ ({rcode}-{fsdiv}): {e}")
                    continue

        # ë¹„ìƒì¥ ë° ë¹„í‘œì¤€ ë¬¸ì„œ ìš°íšŒ(XBRL/PDF) ë¹„í™œì„±í™” ì •ì±…
        # ìƒì¥ì‚¬ ë‹¨ì¼ê³„ì • API ê¸°ì¤€ë§Œ ì‚¬ìš©

        # ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
        unique_attempts = unique(attempted_combinations)
        if best_result:
            result = f"""
## {best_result.get('corp_name')} {bsns_year}ë…„ ì¬ë¬´ì œí‘œ ì¡°íšŒ ê²°ê³¼

âŒ **ìš”ì²­í•œ ì¬ë¬´ì œí‘œ ì—†ìŒ**: {statement_type}

âœ… **ì‚¬ìš© ê°€ëŠ¥í•œ ì¬ë¬´ì œí‘œ**:
{chr(10).join([f"- {stmt}" for stmt in best_result['available_statements']])}

ğŸ“‹ **ì¡°íšŒ ì •ë³´**:
- ë³´ê³ ì„œ: {_get_report_name(best_result['report_code'])}
- ì¬ë¬´ì œí‘œ êµ¬ë¶„: {"ì—°ê²°" if best_result['fs_div'] == "CFS" else "ë³„ë„"}
- ì´ ë°ì´í„° ìˆ˜: {best_result['total_records']}ê°œ

ğŸ” ê³µì‹œ ìš°ì„  íƒì§€: {('ì •ê¸°(A)' if preferred_source=='A' else 'ê°ì‚¬(F)') if preferred_source else 'ì—†ìŒ'}
"""
        else:
            result = f"""
## {display_name or corp_code} {bsns_year}ë…„ ì¬ë¬´ì œí‘œ ì¡°íšŒ ì‹¤íŒ¨

âŒ **ë°ì´í„° ì—†ìŒ**: í•´ë‹¹ ê¸°ì—…ì˜ {bsns_year}ë…„ ì¬ë¬´ì œí‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ğŸ” ê³µì‹œ ìš°ì„  íƒì§€: {('ì •ê¸°(A)' if preferred_source=='A' else 'ê°ì‚¬(F)') if preferred_source else 'ì—†ìŒ'}
ğŸ” **ì‹œë„í•œ ì¡°í•©**: {', '.join(unique_attempts)}

ğŸ’¡ **ê°€ëŠ¥í•œ ì›ì¸**:
- í•´ë‹¹ ì—°ë„ì˜ ê³µì‹œ ë°ì´í„°ê°€ ì•„ì§ ë“±ë¡ë˜ì§€ ì•ŠìŒ
- ê¸°ì—…ì´ í•´ë‹¹ ì—°ë„ì— ê³µì‹œ ì˜ë¬´ê°€ ì—†ì—ˆìŒ
- ë‹¤ë¥¸ ì—°ë„ (ì˜ˆ: {int(bsns_year)-1}ë…„, {int(bsns_year)-2}ë…„)ì˜ ë°ì´í„°ëŠ” ìˆì„ ìˆ˜ ìˆìŒ

ğŸ”„ **ëŒ€ì•ˆ**: ë‹¤ë¥¸ ì—°ë„ë¡œ ì¡°íšŒí•˜ê±°ë‚˜ DART ì „ìê³µì‹œì‹œìŠ¤í…œì—ì„œ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”.
"""

        return [types.TextContent(type="text", text=result)]

    except Exception as e:
        return [types.TextContent(type="text", text=f"ì¬ë¬´ì œí‘œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°
async def get_financial_ratios(corp_name: Optional[str], bsns_year: str, ratio_categories: List[str], include_industry_avg: bool, corp_code: Optional[str] = None) -> List[types.TextContent]:
    """ì¬ë¬´ë¹„ìœ¨ ê³„ì‚° ë° ì¡°íšŒ (ROE, ROA, ë¶€ì±„ë¹„ìœ¨, ìœ ë™ë¹„ìœ¨ ë“±)
    - ê³„ì •ëª…/í‘œ ì–‘ì‹ í¸ì°¨ë¥¼ ê³ ë ¤í•´ ë‹¤ì¤‘ íŒ¨í„´ ë° í¬ê´„ì†ìµê³„ì‚°ì„œê¹Œì§€ íƒìƒ‰
    - (1,234) í˜•ì‹ ìŒìˆ˜ ì²˜ë¦¬, '-' ë¬´ì‹œ ì²˜ë¦¬
    - ì—°ê°„ ë³´ê³ ì„œ(CFS) ê¸°ì¤€, í•„ìš” ì‹œ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ ë³´ì¡° ì¡°íšŒ
    """
    try:
        corp_code = corp_code or (await get_corp_code(corp_name))

        def parse_amount(val: str) -> float:
            if not val or val == '-':
                return 0.0
            s = str(val).replace(',', '').strip()
            neg = s.startswith('(') and s.endswith(')')
            if neg:
                s = s[1:-1]
            try:
                num = float(s)
            except Exception:
                return 0.0
            return -num if neg else num

        def fetch_df(reprt_code: str, fs_div: str) -> pd.DataFrame:
            url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
            params = {
                'crtfc_key': API_KEY,
                'corp_code': corp_code,
                'bsns_year': bsns_year,
                'reprt_code': reprt_code,
                'fs_div': fs_div,
            }
            resp = requests.get(url, params=params)
            j = resp.json()
            if j.get('status') != '000':
                return pd.DataFrame()
            return pd.DataFrame(j.get('list', []))

        # ìš°ì„  ì¡°í•©ë“¤: ì—°ê°„/ì—°ê²° â†’ ì—°ê°„/ë³„ë„ â†’ 3ë¶„ê¸°/ì—°ê²°
        tried: List[tuple[str, str]] = [('11014', 'CFS'), ('11014', 'OFS'), ('11013', 'CFS')]
        df = pd.DataFrame()
        for rc, fd in tried:
            df = fetch_df(rc, fd)
            if not df.empty:
                break
        if df.empty:
            return [types.TextContent(type='text', text='ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì—°ë„/ë³´ê³ ì„œ ì½”ë“œë¥¼ ë³€ê²½í•´ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')]

        def get_value(sj_candidates: List[str], account_patterns: List[str]) -> float:
            target = df[df['sj_nm'].isin(sj_candidates)] if 'sj_nm' in df.columns else df
            if target.empty:
                return 0.0
            for pattern in account_patterns:
                try:
                    m = target[target['account_nm'].str.contains(pattern, na=False, regex=True)]
                except Exception:
                    continue
                if not m.empty:
                    # thstrm ìš°ì„ , ì—†ìœ¼ë©´ ê³¼ê±° í•­ëª© ë³´ì¡° ì¡°íšŒ
                    for col in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount']:
                        if col in m.columns:
                            val = m.iloc[0][col]
                            amt = parse_amount(val)
                            if amt != 0.0:
                                return amt
            return 0.0

        # ê³„ì • ì¶”ì¶œ
        total_assets = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìì‚°ì´ê³„'])
        total_equity = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìë³¸ì´ê³„'])
        total_liabilities = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ë¶€ì±„ì´ê³„'])
        current_assets = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìœ ë™ìì‚°'])
        current_liabilities = get_value(['ì¬ë¬´ìƒíƒœí‘œ'], ['ìœ ë™ë¶€ì±„'])

        revenue = get_value(['ì†ìµê³„ì‚°ì„œ', 'í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë§¤ì¶œì•¡', 'ìˆ˜ìµ\(ë§¤ì¶œì•¡\)', 'ì˜ì—…ìˆ˜ìµ'])
        operating_profit = get_value(['ì†ìµê³„ì‚°ì„œ', 'í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ì˜ì—…ì´ìµ'])
        net_profit = get_value(['ì†ìµê³„ì‚°ì„œ', 'í¬ê´„ì†ìµê³„ì‚°ì„œ'], [
            'ë‹¹ê¸°ìˆœì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ\(ì†ì‹¤\)', 'ì§€ë°°ì£¼ì£¼ì§€ë¶„\s*ìˆœì´ìµ', 'ì§€ë°°ê¸°ì—…\s*ì†Œìœ ì£¼ì§€ë¶„\s*ìˆœì´ìµ', 'ì—°ê²°ë‹¹ê¸°ìˆœì´ìµ'
        ])

        ratios: Dict[str, Dict[str, float]] = {}
        if 'profitability' in ratio_categories:
            ratios['profitability'] = {}
            if total_equity > 0 and net_profit != 0:
                ratios['profitability']['ROE'] = round((net_profit / total_equity) * 100, 2)
            if total_assets > 0 and net_profit != 0:
                ratios['profitability']['ROA'] = round((net_profit / total_assets) * 100, 2)
            if revenue > 0:
                ratios['profitability']['ì˜ì—…ì´ìµë¥ '] = round((operating_profit / revenue) * 100, 2)
                if net_profit != 0:
                    ratios['profitability']['ìˆœì´ìµë¥ '] = round((net_profit / revenue) * 100, 2)
        if 'stability' in ratio_categories:
            ratios['stability'] = {}
            if total_equity > 0 and total_liabilities >= 0:
                ratios['stability']['ë¶€ì±„ë¹„ìœ¨'] = round((total_liabilities / total_equity) * 100, 2)
            if current_liabilities > 0:
                ratios['stability']['ìœ ë™ë¹„ìœ¨'] = round((current_assets / current_liabilities) * 100, 2)
            if total_assets > 0 and total_equity >= 0:
                ratios['stability']['ìê¸°ìë³¸ë¹„ìœ¨'] = round((total_equity / total_assets) * 100, 2)
        if 'activity' in ratio_categories and total_assets > 0 and revenue > 0:
            ratios.setdefault('activity', {})['ì´ìì‚°íšŒì „ìœ¨'] = round(revenue / total_assets, 2)

        # ê²°ê³¼ êµ¬ì„±
        result = f"## {corp_name} {bsns_year}ë…„ ì¬ë¬´ë¹„ìœ¨ ë¶„ì„\n\n"
        names = {'profitability': 'ìˆ˜ìµì„± ì§€í‘œ', 'stability': 'ì•ˆì •ì„± ì§€í‘œ', 'activity': 'í™œë™ì„± ì§€í‘œ', 'growth': 'ì„±ì¥ì„± ì§€í‘œ'}
        for cat, vals in ratios.items():
            result += f"### {names.get(cat, cat)}\n\n"
            for k, v in vals.items():
                suffix = '%' if k not in ['ì´ìì‚°íšŒì „ìœ¨'] else ''
                result += f"- **{k}**: {v}{suffix}\n"
            result += "\n"
        if not ratios:
            result += "- ìœ íš¨í•œ ì§€í‘œë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—°ë„/ë³´ê³ ì„œ ì½”ë“œë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì¬ë¬´ì œí‘œ êµ¬ë¶„ì„ ì‹œë„í•´ ì£¼ì„¸ìš”.\n"
        return [types.TextContent(type='text', text=result)]
    except Exception as e:
        return [types.TextContent(type='text', text=f"ì¬ë¬´ë¹„ìœ¨ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ì‹œê³„ì—´ ë¶„ì„ (ë˜í¼)
async def analyze_time_series(corp_name: str, analysis_period: int, metrics: List[str], forecast_periods: int) -> List[types.TextContent]:
    """ê¸°ì—…ì˜ ì¬ë¬´ ì„±ê³¼ ì‹œê³„ì—´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤
    - ì²« í˜¸ì¶œì—ì„œ ì‹¤ì œ DART ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ ìˆ˜ì§‘í•˜ì—¬ ì‚¬ìš©(ì—°ê°„ ë³´ê³ ì„œ ê¸°ì¤€)
    - ë§¤ì¶œì•¡/ì˜ì—…ì´ìµ/ìˆœì´ìµì„ ìµœê·¼ Në…„ ìˆ˜ì§‘, ëˆ„ë½ ë…„ë„ëŠ” ê±´ë„ˆëœ€
    """
    try:
        if not API_KEY:
            return [types.TextContent(type='text', text='âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.')]

        corp_code = await get_corp_code(corp_name)
        # ìµœê·¼ analysis_periodë…„ (ì˜¬í•´-1 ê¸°ì¤€) ì—­ì‚° ìˆ˜ì§‘
        end_year = datetime.now().year - 1
        years = list(range(end_year - analysis_period + 1, end_year + 1))

        def parse_amount(val: str) -> float:
            if not val or val == '-':
                return 0.0
            s = str(val).replace(',', '').strip()
            neg = s.startswith('(') and s.endswith(')')
            if neg:
                s = s[1:-1]
            try:
                num = float(s)
            except Exception:
                return 0.0
            return -num if neg else num

        def fetch_year(year: int) -> dict:
            url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
            params = {'crtfc_key': API_KEY,'corp_code': corp_code,'bsns_year': str(year),'reprt_code': '11014','fs_div': 'CFS'}
            j = requests.get(url, params=params).json()
            if j.get('status') != '000':
                return {}
            df = pd.DataFrame(j.get('list', []))
            if df.empty:
                return {}
            def get_value(sj_candidates, patterns):
                target = df[df['sj_nm'].isin(sj_candidates)] if 'sj_nm' in df.columns else df
                for pattern in patterns:
                    try:
                        m = target[target['account_nm'].str.contains(pattern, na=False, regex=True)]
                    except Exception:
                        m = pd.DataFrame()
                    if not m.empty:
                        for col in ['thstrm_amount','frmtrm_amount','bfefrmtrm_amount']:
                            if col in m.columns:
                                amt = parse_amount(m.iloc[0][col])
                                if amt != 0.0:
                                    return amt
                if 'account_id' in target.columns:
                    for pid in ['Revenue','Sales','OperatingIncome','ProfitLoss','NetIncome', 'ProfitLossAttributableToOwnersOfParent']:
                        m2 = target[target['account_id'].str.contains(pid, na=False)]
                        if not m2.empty:
                            for col in ['thstrm_amount','frmtrm_amount','bfefrmtrm_amount']:
                                if col in m2.columns:
                                    amt = parse_amount(m2.iloc[0][col])
                                    if amt != 0.0:
                                        return amt
                return 0.0
            revenue = get_value(['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë§¤ì¶œì•¡','ìˆ˜ìµ\(ë§¤ì¶œì•¡\)','ì˜ì—…ìˆ˜ìµ'])
            operating = get_value(['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ì˜ì—…ì´ìµ'])
            net = get_value(['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë‹¹ê¸°ìˆœì´ìµ','ë‹¹ê¸°ìˆœì´ìµ\(ì†ì‹¤\)','ì§€ë°°ì£¼ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì§€ë°°ê¸°ì—…\s*ì†Œìœ ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì—°ê²°ë‹¹ê¸°ìˆœì´ìµ'])
            return {'year': year, 'ë§¤ì¶œì•¡': revenue, 'ì˜ì—…ì´ìµ': operating, 'ìˆœì´ìµ': net}

        collected = [fetch_year(y) for y in years]
        collected = [c for c in collected if c]
        if not collected:
            return [types.TextContent(type='text', text='ì‹œê³„ì—´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ê°„ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')]

        dates = [f"{c['year']}-12-31" for c in collected]
        financial_data = {
            'dates': dates,
            'ë§¤ì¶œì•¡': [c['ë§¤ì¶œì•¡'] for c in collected],
            'ì˜ì—…ì´ìµ': [c['ì˜ì—…ì´ìµ'] for c in collected],
            'ìˆœì´ìµ': [c['ìˆœì´ìµ'] for c in collected],
        }

        trend_result = await time_series_analyzer.analyze_financial_trends(corp_name, financial_data, len(collected), metrics)
        forecast_result = await time_series_analyzer.forecast_performance(corp_name, financial_data, forecast_periods, metrics)

        text = f"""# ğŸ“ˆ {corp_name} ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ë¶„ì„ ê¸°ê°„**: {len(collected)}ë…„ (ì—°ê°„)
- **ë¶„ì„ ì§€í‘œ**: {', '.join(metrics)}
- **ë°ì´í„° í¬ì¸íŠ¸**: {trend_result.get('data_points', 0)}ê°œ
- **ì˜ˆì¸¡ ê¸°ê°„**: {forecast_periods}ë¶„ê¸°
"""
        for metric, analysis in (trend_result.get('trend_results', {}) or {}).items():
            basic = analysis.get('basic_stats', {})
            trend = analysis.get('trend_analysis', {})
            text += f"\n### {metric}\n- **í‰ê· ê°’**: {basic.get('mean', 0):,.1f}\n- **ì„±ì¥ë¥  (CAGR)**: {basic.get('growth_rate', {}).get('cagr', 0):.1f}%\n- **íŠ¸ë Œë“œ ë°©í–¥**: {trend.get('direction', 'N/A')}\n- **íŠ¸ë Œë“œ ê°•ë„**: {trend.get('strength', 0):.2f}\n"
        return [types.TextContent(type='text', text=text)]
    except Exception as e:
        logger.error(f"ì‹œê³„ì—´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return [types.TextContent(type='text', text=f"âŒ ì‹œê³„ì—´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ (ë˜í¼)
async def compare_with_industry(corp_name: str, industry: str, comparison_metrics: List[str], analysis_type: str) -> List[types.TextContent]:
    """ê¸°ì—…ì„ ë™ì¢… ì—…ê³„ì™€ ë²¤ì¹˜ë§ˆí¬ ë¹„êµí•©ë‹ˆë‹¤ (ì‹¤ë°ì´í„° í‘œ ì¶œë ¥)"""
    try:
        if not API_KEY:
            return [types.TextContent(type='text', text='âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.')]

        result = await benchmark_analyzer.compare_with_industry(corp_name, industry, comparison_metrics)
        bench = result.get('benchmark_results', {}) or {}
        companies = list(bench.keys())

        # í‘œ êµ¬ì„±: ì§€í‘œ í–‰, ê¸°ì—… ì—´
        rows = []
        metric_order = [
            'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ', 'ROE', 'ROA', 'ë¶€ì±„ë¹„ìœ¨', 'ìœ ë™ë¹„ìœ¨', 'ì˜ì—…ì´ìµë¥ '
        ]
        # ìš”ì²­ ì§€í‘œ ìš°ì„  ë°°ì¹˜
        ordered_metrics = [m for m in metric_order if m in set(comparison_metrics + metric_order)]

        header = "| ì§€í‘œ |" + " ".join(f"{c} |" for c in companies)
        sep = "|------|" + ("------|" * len(companies))
        table = [header, sep]
        for m in ordered_metrics:
            row = [f"| **{m}** |"]
            for c in companies:
                v = bench.get(c, {}).get(m)
                if v is None:
                    row.append(" - |")
                else:
                    if m in ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ìˆœì´ìµ']:
                        row.append(f" {v:,.1f}ì–µì› |")
                    elif m in ['ROE', 'ROA', 'ë¶€ì±„ë¹„ìœ¨', 'ìœ ë™ë¹„ìœ¨', 'ì˜ì—…ì´ìµë¥ ']:
                        row.append(f" {v:.2f}% |")
                    else:
                        row.append(f" {v} |")
            table.append("".join(row))

        text = f"""# ğŸ† {corp_name} ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ

## ğŸ“Š ë¹„êµ ê°œìš”
- **ì—…ì¢…**: {industry}
- **ë¹„êµ ì§€í‘œ**: {', '.join(comparison_metrics)}
- **ë¶„ì„ ìœ í˜•**: {analysis_type.title()}

## ğŸ“‹ ì§€í‘œë³„ ë¹„êµ ê²°ê³¼
""" + "\n".join(table)
        return [types.TextContent(type='text', text=text)]
    except Exception as e:
        logger.error(f"ë²¤ì¹˜ë§ˆí¬ ë¹„êµ ì¤‘ ì˜¤ë¥˜: {e}")
        return [types.TextContent(type='text', text=f"âŒ ë²¤ì¹˜ë§ˆí¬ ë¹„êµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ê³µì‹œ ëª©ë¡ ì¡°íšŒ
async def get_disclosure_list(corp_name: Optional[str], bgn_de: str, end_de: str, page_count: int, corp_code: Optional[str] = None) -> List[types.TextContent]:
    """ê³µì‹œ ëª©ë¡ ì¡°íšŒ (corp_code ìš°ì„ )"""
    try:
        corp_code = corp_code or (await get_corp_code(corp_name))
        url = 'https://opendart.fss.or.kr/api/list.json'
        params = {
            'crtfc_key': API_KEY,
            'corp_code': corp_code,
            'bgn_de': bgn_de,
            'end_de': end_de,
            'page_count': page_count,
        }
        response = requests.get(url, params=params)
        data = response.json()
        if data.get('status') != '000':
            return [types.TextContent(type="text", text=f"ì˜¤ë¥˜: {data.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")]
        disclosures = data.get('list', [])
        result = f"## {corp_name} ê³µì‹œ ëª©ë¡ ({bgn_de} ~ {end_de})\n\n"
        for disclosure in disclosures:
            result += f"- **{disclosure.get('report_nm','')}** ({disclosure.get('rcept_dt','')})\n"
            result += f"  - ì ‘ìˆ˜ë²ˆí˜¸: {disclosure.get('rcept_no','')}\n"
            result += f"  - ì œì¶œì¸: {disclosure.get('flr_nm','')}\n\n"
        return [types.TextContent(type="text", text=result)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"ê³µì‹œ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ê¸°ì—… ê°„ ì¬ë¬´ì§€í‘œ ë¹„êµ
async def compare_financials(companies: List[str], bsns_year: str, comparison_metrics: List[str], visualization: bool = True, corp_codes: Optional[List[str]] = None) -> List[types.TextContent]:
    """ì—¬ëŸ¬ ê¸°ì—…ì˜ ì¬ë¬´ì§€í‘œë¥¼ ë¹„êµ
    - í•œê¸€/ì˜ë¬¸ ì§€í‘œëª…ì„ ëª¨ë‘ í—ˆìš©í•˜ê³  ë‚´ë¶€ í‘œì¤€ í‚¤ë¡œ ì •ê·œí™”
    - ë‹¤ì¤‘ ë³´ê³ ì„œ ì¡°í•© ë° í¬ê´„ì†ìµê³„ì‚°ì„œê¹Œì§€ íƒìƒ‰í•˜ì—¬ ëˆ„ë½ ìµœì†Œí™”
    """
    try:
        # 1) ì§€í‘œ ì •ê·œí™”
        metric_alias = {
            'ë§¤ì¶œì•¡': 'revenue', 'revenue': 'revenue',
            'ì˜ì—…ì´ìµ': 'operating_profit', 'operating_profit': 'operating_profit',
            'ìˆœì´ìµ': 'net_profit', 'net_profit': 'net_profit',
            'ROE': 'roe', 'roe': 'roe',
            'ë¶€ì±„ë¹„ìœ¨': 'debt_ratio', 'debt_ratio': 'debt_ratio',
            'ì˜ì—…ì´ìµë¥ ': 'operating_margin', 'operating_margin': 'operating_margin',
        }
        normalized = [metric_alias.get(m, m) for m in comparison_metrics]
        wanted = set(normalized)

        # 2) í—¬í¼: ë°ì´í„° íšë“
        def parse_amount(val: str) -> float:
            if not val or val == '-':
                return 0.0
            s = str(val).replace(',', '').strip()
            neg = s.startswith('(') and s.endswith(')')
            if neg:
                s = s[1:-1]
            try:
                num = float(s)
            except Exception:
                return 0.0
            return -num if neg else num

        def fetch_df(corp_code: str, reprt_code: str, fs_div: str) -> pd.DataFrame:
            url = 'https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json'
            params = {'crtfc_key': API_KEY,'corp_code': corp_code,'bsns_year': bsns_year,'reprt_code': reprt_code,'fs_div': fs_div}
            j = requests.get(url, params=params).json()
            if j.get('status') != '000':
                return pd.DataFrame()
            return pd.DataFrame(j.get('list', []))

        def get_value(df: pd.DataFrame, sj_candidates: List[str], patterns: List[str]) -> float:
            target = df[df['sj_nm'].isin(sj_candidates)] if 'sj_nm' in df.columns else df
            if target.empty:
                return 0.0
            # 1) ê³„ì •ëª…ìœ¼ë¡œ ìš°ì„  ë§¤ì¹­
            for pattern in patterns:
                try:
                    m = target[target['account_nm'].str.contains(pattern, na=False, regex=True)]
                except Exception:
                    m = pd.DataFrame()
                if not m.empty:
                    for col in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount']:
                        if col in m.columns:
                            amt = parse_amount(m.iloc[0][col])
                            if amt != 0.0:
                                return amt
            # 2) account_idë¡œ ë³´ì¡° ë§¤ì¹­ (IFRS í‘œì¤€ ì½”ë“œ)
            if 'account_id' in target.columns:
                id_patterns = ['ProfitLoss', 'NetIncome', 'ComprehensiveIncome', 'ProfitLossAttributableToOwnersOfParent']
                for pid in id_patterns:
                    m2 = target[target['account_id'].str.contains(pid, na=False, regex=False)]
                    if not m2.empty:
                        for col in ['thstrm_amount', 'frmtrm_amount', 'bfefrmtrm_amount']:
                            if col in m2.columns:
                                amt = parse_amount(m2.iloc[0][col])
                                if amt != 0.0:
                                    return amt
            return 0.0

        # 3) ê° íšŒì‚¬ë³„ ìˆ˜ì§‘/ê³„ì‚°
        comparison_data: Dict[str, Dict[str, Any]] = {}
        for idx, company in enumerate(companies):
            try:
                corp_code = (corp_codes[idx] if corp_codes and idx < len(corp_codes) and corp_codes[idx] else None) or (await get_corp_code(company))
                df = pd.DataFrame()
                for rc, fd in [('11014','CFS'), ('11014','OFS'), ('11013','CFS')]:
                    df = fetch_df(corp_code, rc, fd)
                    if not df.empty:
                        break
                if df.empty:
                    comparison_data[company] = {'ì˜¤ë¥˜': 'ë°ì´í„° ì—†ìŒ'}
                    continue

                total_assets = get_value(df, ['ì¬ë¬´ìƒíƒœí‘œ'], ['ìì‚°ì´ê³„'])
                total_equity = get_value(df, ['ì¬ë¬´ìƒíƒœí‘œ'], ['ìë³¸ì´ê³„'])
                total_liabilities = get_value(df, ['ì¬ë¬´ìƒíƒœí‘œ'], ['ë¶€ì±„ì´ê³„'])
                revenue = get_value(df, ['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë§¤ì¶œì•¡','ìˆ˜ìµ\(ë§¤ì¶œì•¡\)','ì˜ì—…ìˆ˜ìµ'])
                operating_profit = get_value(df, ['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ì˜ì—…ì´ìµ'])
                net_profit = get_value(df, ['ì†ìµê³„ì‚°ì„œ','í¬ê´„ì†ìµê³„ì‚°ì„œ'], ['ë‹¹ê¸°ìˆœì´ìµ','ë‹¹ê¸°ìˆœì´ìµ\(ì†ì‹¤\)','ì§€ë°°ì£¼ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì§€ë°°ê¸°ì—…\s*ì†Œìœ ì£¼ì§€ë¶„\s*ìˆœì´ìµ','ì—°ê²°ë‹¹ê¸°ìˆœì´ìµ'])

                metrics: Dict[str, Any] = {}
                if 'revenue' in wanted:
                    metrics['ë§¤ì¶œì•¡'] = revenue / 100000000
                if 'operating_profit' in wanted:
                    metrics['ì˜ì—…ì´ìµ'] = operating_profit / 100000000
                if 'net_profit' in wanted:
                    metrics['ìˆœì´ìµ'] = net_profit / 100000000
                if 'roe' in wanted and total_equity > 0 and net_profit != 0:
                    metrics['ROE'] = (net_profit / total_equity) * 100
                if 'debt_ratio' in wanted and total_equity > 0:
                    metrics['ë¶€ì±„ë¹„ìœ¨'] = (total_liabilities / total_equity) * 100
                if 'operating_margin' in wanted and revenue > 0:
                    metrics['ì˜ì—…ì´ìµë¥ '] = (operating_profit / revenue) * 100
                comparison_data[company] = metrics
            except Exception as company_error:
                comparison_data[company] = {"ì˜¤ë¥˜": str(company_error)}

        # 4) í‘œ ìƒì„±
        result = f"## ê¸°ì—… ì¬ë¬´ì§€í‘œ ë¹„êµ ({bsns_year}ë…„)\n\n"
        if not comparison_data:
            return [types.TextContent(type="text", text="ë¹„êµí•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")]
        metrics_list = set()
        for d in comparison_data.values():
            if isinstance(d, dict):
                metrics_list.update(d.keys())
        metrics_list = [m for m in ['ë§¤ì¶œì•¡','ì˜ì—…ì´ìµ','ìˆœì´ìµ','ROE','ë¶€ì±„ë¹„ìœ¨','ì˜ì—…ì´ìµë¥ '] if m in metrics_list]

        result += "| ì§€í‘œ |" + " ".join(f"{c} |" for c in companies) + "\n"
        result += "|------|" + ("------|" * len(companies)) + "\n"
        for metric in metrics_list:
            result += f"| **{metric}** |"
            for company in companies:
                val = comparison_data.get(company, {}).get(metric)
                if val is None:
                    result += " - |"
                    continue
                if isinstance(val, float):
                    if metric in ['ë§¤ì¶œì•¡','ì˜ì—…ì´ìµ','ìˆœì´ìµ']:
                        result += f" {val:,.1f}ì–µì› |"
                    elif metric in ['ROE','ë¶€ì±„ë¹„ìœ¨','ì˜ì—…ì´ìµë¥ ']:
                        result += f" {val:.2f}% |"
                    else:
                        result += f" {val:.2f} |"
                else:
                    result += f" {val} |"
            result += "\n"

        if visualization:
            # ê°„ë‹¨í•œ ì°¨íŠ¸ ë°ì´í„°(ë§‰ëŒ€ ê·¸ë˜í”„ìš©) í¬í•¨
            chart = {
                'metrics': metrics_list,
                'series': {company: [comparison_data.get(company, {}).get(m) for m in metrics_list] for company in companies}
            }
            result += "\n### ì‹œê°í™” ë°ì´í„°\n" + json.dumps(chart, ensure_ascii=False)
        return [types.TextContent(type="text", text=result)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"ì¬ë¬´ì§€í‘œ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: ë‰´ìŠ¤/ê°ì„±/ì´ë²¤íŠ¸ ë„êµ¬ ë˜í¼
async def get_company_news(corp_name: str, search_period: str, news_categories: List[str], include_sentiment: bool) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        news_data = await news_analyzer.search_company_news(corp_name, search_period)
        result_text = f"""# ğŸ“° {corp_name} ìµœê·¼ ë‰´ìŠ¤ ë¶„ì„

## ğŸ“Š ìˆ˜ì§‘ ì •ë³´
- **ê²€ìƒ‰ ê¸°ê°„**: {search_period}
- **ìˆ˜ì§‘ëœ ê¸°ì‚¬**: {news_data.get('total_articles', 0)}ê°œ
- **ë°ì´í„° ì¶œì²˜**: {news_data.get('data_source', 'N/A')}
- **ìˆ˜ì§‘ ì‹œì **: {news_data.get('search_timestamp', 'N/A')}

## ğŸ“‹ ì£¼ìš” ë‰´ìŠ¤
"""
        for i, article in enumerate(news_data.get('articles', [])[:5], 1):
            result_text += f"""### {i}. {article.get('title', 'N/A')}
- **ë°œí–‰ì¼**: {article.get('published_date', 'N/A')}
- **ì¶œì²˜**: {article.get('source', 'N/A')}
- **ë‚´ìš©**: {article.get('content', 'N/A')[:200]}...

"""
        if include_sentiment:
            total_articles = len(news_data.get('articles', []))
            if total_articles > 0:
                positive_count = sum(1 for article in news_data.get('articles', []) if any(word in (article.get('title','') + article.get('content','')).lower() for word in ['ì„±ì¥','ì¦ê°€','ìƒìŠ¹','ì„±ê³µ','ê¸ì •']))
                sentiment_ratio = positive_count / total_articles
                sentiment_summary = 'ê¸ì •ì ' if sentiment_ratio > 0.6 else 'ë¶€ì •ì ' if sentiment_ratio < 0.4 else 'ì¤‘ë¦½ì '
                result_text += f"## ğŸ’­ ê°ì„± ë¶„ì„ ìš”ì•½\n- **ì „ì²´ ê°ì„±**: {sentiment_summary}\n- **ê¸ì •ì  ê¸°ì‚¬ ë¹„ìœ¨**: {sentiment_ratio:.1%}\n"
        result_text += f"\n---\n*ë¶„ì„ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        return [types.TextContent(type="text", text=result_text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def analyze_news_sentiment(corp_name: str, search_period: str, analysis_depth: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        sentiment_result = await news_analyzer.analyze_company_news_sentiment(corp_name, search_period, analysis_depth)
        result_text = f"""# ğŸ’­ {corp_name} ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê²°ê³¼

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ë¶„ì„ ê¸°ê°„**: {sentiment_result.get('analysis_period', 'N/A')}
- **ë¶„ì„ ê¹Šì´**: {sentiment_result.get('analysis_depth', 'N/A')}
- **ë¶„ì„ ê¸°ì‚¬ ìˆ˜**: {sentiment_result.get('total_articles_analyzed', 0)}ê°œ
- **í‰ê·  ê°ì„± ì ìˆ˜**: {sentiment_result.get('average_sentiment_score', 0):.3f}

## ğŸ¯ ê°ì„± ë¶„í¬
- **ê¸ì •**: {sentiment_result.get('sentiment_distribution', {}).get('positive', 0)}ê°œ
- **ì¤‘ë¦½**: {sentiment_result.get('sentiment_distribution', {}).get('neutral', 0)}ê°œ
- **ë¶€ì •**: {sentiment_result.get('sentiment_distribution', {}).get('negative', 0)}ê°œ
"""
        for article in sentiment_result.get('article_sentiments', [])[:5]:
            result_text += f"""\n### {article.get('title', 'N/A')}
- **ê°ì„± ì ìˆ˜**: {article.get('sentiment_score', 0):.3f}
- **ê°ì„± ë¶„ë¥˜**: {article.get('sentiment_label', 'N/A')}
- **í‚¤ì›Œë“œ**: {', '.join(article.get('detected_keywords', [])[:3])}
"""
        result_text += f"\n---\n*ë¶„ì„ ì™„ë£Œ: {sentiment_result.get('analysis_timestamp', 'N/A')}*\n*ë°ì´í„° ì¶œì²˜: {sentiment_result.get('data_source', 'N/A')}*\n"
        return [types.TextContent(type="text", text=result_text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def detect_financial_events(corp_name: str, monitoring_period: int, event_types: List[str]) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        events_result = await news_analyzer.detect_market_events(corp_name, monitoring_period)
        result_text = f"""# ğŸ¯ {corp_name} ì¬ë¬´ ì´ë²¤íŠ¸ íƒì§€ ê²°ê³¼

## ğŸ“Š íƒì§€ ê°œìš”
- **ëª¨ë‹ˆí„°ë§ ê¸°ê°„**: {events_result.get('monitoring_period_days', 0)}ì¼
- **íƒì§€ëœ ì´ë²¤íŠ¸**: {events_result.get('total_events_detected', 0)}ê°œ
- **ì´ë²¤íŠ¸ ìœ í˜•**: {', '.join(events_result.get('event_types_found', []))}

## ğŸ“‹ ì´ë²¤íŠ¸ ìƒì„¸
"""
        for event_type, events in (events_result.get('event_summary', {}) or {}).items():
            event_name = event_type.replace('_', ' ').title()
            result_text += f"### {event_name}\n- **íƒì§€ ê±´ìˆ˜**: {len(events)}ê°œ\n"
            for event in events[:3]:
                result_text += f"  - {event.get('article_title','N/A')} ({event.get('article_date','N/A')})\n"
            result_text += "\n"
        if not events_result.get('event_summary'):
            result_text += "- íƒì§€ëœ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        result_text += f"\n---\n*íƒì§€ ì™„ë£Œ: {events_result.get('detection_timestamp', 'N/A')}*\n*ë°ì´í„° ì¶œì²˜: {events_result.get('data_source', 'N/A')}*\n"
        return [types.TextContent(type="text", text=result_text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ì´ë²¤íŠ¸ íƒì§€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: íˆ¬ì ì‹ í˜¸ ë° ë¦¬í¬íŠ¸
async def generate_investment_signal(corp_name: str, analysis_period: int, weight_config: Dict[str, float], risk_tolerance: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        # ê°„ì†Œí™”: ê±´ê°•ì„±/ë‰´ìŠ¤/ì´ë²¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ì•„ ì ìˆ˜í™” (ìƒì„¸ ë¡œì§ì€ backup ì°¸ê³ )
        # ì—¬ê¸°ì„œëŠ” news_analyzerì™€ ê°„ë‹¨í•œ ê°€ì¤‘ í•©ìœ¼ë¡œ ëŒ€ì²´
        sentiment = await news_analyzer.analyze_company_news_sentiment(corp_name, "week", "detailed")
        avg_sent = sentiment.get('average_sentiment_score', 0.0)
        total_score = 50 + avg_sent * 50
        signal = 'STRONG BUY' if total_score >= 85 else 'BUY' if total_score >= 70 else 'HOLD' if total_score >= 50 else 'SELL'
        text = f"""# ğŸ¯ {corp_name} íˆ¬ì ì‹ í˜¸ ë¶„ì„

## ğŸ“Š ì¢…í•© íˆ¬ì ì‹ í˜¸
- **ì‹ í˜¸**: {signal}
- **ì‹ í˜¸ ì ìˆ˜**: {total_score:.1f}/100ì 
- **ë¦¬ìŠ¤í¬ í—ˆìš©ë„**: {risk_tolerance.title()}

## ğŸ’¡ ìš”ì•½
- ìµœê·¼ ë‰´ìŠ¤ ê°ì„± ê¸°ë°˜ ê°„ë‹¨ ì‹ í˜¸ì…ë‹ˆë‹¤. ìƒì„¸ ì¢…í•© ë¶„ì„ ë¡œì§ì€ ì°¨í›„ ê³ ë„í™” ì˜ˆì •ì…ë‹ˆë‹¤.
"""
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ íˆ¬ì ì‹ í˜¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def generate_summary_report(corp_name: str, report_type: str, include_charts: bool, analysis_depth: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        # ê°„ë‹¨ ë˜í¼: ëª¨ë“ˆì—ì„œ ë¦¬í¬íŠ¸ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì€ report_generator ë‚´ë¶€)
        analysis_data = {"corp_name": corp_name, "analysis_depth": analysis_depth}
        report_result = await report_generator.generate_comprehensive_report(corp_name, analysis_data)
        if report_result.get('success'):
            return [types.TextContent(type="text", text=report_result.get('report_content',''))]
        return [types.TextContent(type="text", text=f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {report_result.get('metadata',{}).get('error','ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def export_to_pdf(corp_name: str, report_content: str, include_metadata: bool, page_format: str) -> List[types.TextContent]:
    try:
        try:
            from reportlab.lib.pagesizes import letter, A4
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
            from reportlab.lib.styles import getSampleStyleSheet
            import io, base64
        except Exception:
            return [types.TextContent(type="text", text="âŒ PDF ìƒì„±ì„ ìœ„í•œ reportlab ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")]
        buffer = io.BytesIO()
        page_size = A4 if page_format == "A4" else letter
        doc = SimpleDocTemplate(buffer, pagesize=page_size)
        styles = getSampleStyleSheet()
        story = [Paragraph(f"{corp_name} ê¸°ì—… ë¶„ì„ ë¦¬í¬íŠ¸", styles['Title']), Spacer(1, 12)]
        if include_metadata:
            story.append(Paragraph(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), styles['Normal']))
            story.append(Spacer(1, 12))
        for line in report_content.split('\n'):
            if line.strip():
                story.append(Paragraph(line, styles['Normal']))
                story.append(Spacer(1, 6))
        doc.build(story)
        pdf_data = buffer.getvalue(); buffer.close()
        pdf_base64 = base64.b64encode(pdf_data).decode('utf-8')
        text = f"""# ğŸ“„ PDF ë‚´ë³´ë‚´ê¸° ì™„ë£Œ

- **ê¸°ì—…ëª…**: {corp_name}
- **íŒŒì¼ í¬ê¸°**: {len(pdf_data):,} bytes

```
{pdf_base64[:200]}...
```
"""
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ PDF ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

# ì¶”ê°€ ê¸°ëŠ¥: í¬íŠ¸í´ë¦¬ì˜¤/ê²½ìŸ/ì—…ê³„ ë¦¬í¬íŠ¸
async def optimize_portfolio(companies: List[str], investment_amount: int, risk_tolerance: str, optimization_method: str) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        portfolio_result = await portfolio_analyzer.optimize_portfolio(companies, investment_amount, risk_tolerance, optimization_method)
        text = f"""# ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê²°ê³¼

## ğŸ¯ ìµœì í™” ì„¤ì •
- **ê¸°ì—… êµ¬ì„±**: {', '.join(companies)}
- **ì´ íˆ¬ìê¸ˆì•¡**: {investment_amount:,}ì›
- **ë¦¬ìŠ¤í¬ í—ˆìš©ë„**: {risk_tolerance.title()}
- **ìµœì í™” ë°©ë²•**: {optimization_method.title()}

## ğŸ’° ìµœì  íˆ¬ì ë¹„ì¤‘
"""
        for company, weight in (portfolio_result.get('optimal_weights', {}) or {}).items():
            allocation = (portfolio_result.get('allocations', {}) or {}).get(company, 0)
            text += f"- **{company}**: {weight:.1%} ({allocation:,.0f}ì›)\n"
        text += f"\n## ğŸ“ˆ ì˜ˆìƒ ì„±ê³¼\n- **ì—°ê°„ ê¸°ëŒ€ìˆ˜ìµë¥ **: {portfolio_result.get('expected_annual_return', 0):.1f}%\n- **ì—°ê°„ ë³€ë™ì„±**: {portfolio_result.get('annual_volatility', 0):.1f}%\n- **ìƒ¤í”„ ë¹„ìœ¨**: {portfolio_result.get('sharpe_ratio', 0):.2f}\n"
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def analyze_competitive_position(corp_name: str, competitors: List[str], analysis_metrics: List[str], include_swot: bool) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        competitive_result = await benchmark_analyzer.analyze_competitive_position(corp_name, competitors, analysis_metrics)
        text = f"""# âš”ï¸ {corp_name} ê²½ìŸ í¬ì§€ì…˜ ë¶„ì„

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ëŒ€ìƒ ê¸°ì—…**: {corp_name}
- **ê²½ìŸì‚¬**: {', '.join(competitors)}
- **ë¶„ì„ ì§€í‘œ**: {', '.join(analysis_metrics)}
- **ì‹œì¥ í¬ì§€ì…˜**: {competitive_result.get('market_position', 'N/A')}
"""
        if include_swot and 'swot_analysis' in competitive_result:
            swot = competitive_result['swot_analysis']
            text += f"""\n## ğŸ¯ SWOT ë¶„ì„

### âš¡ ê°•ì  (Strengths)
{chr(10).join(f"- {s}" for s in swot.get('strengths', []))}

### âš ï¸ ì•½ì  (Weaknesses)
{chr(10).join(f"- {w}" for w in swot.get('weaknesses', []))}

### ğŸŒŸ ê¸°íšŒ (Opportunities)
{chr(10).join(f"- {o}" for o in swot.get('opportunities', []))}

### ğŸš¨ ìœ„í˜‘ (Threats)
{chr(10).join(f"- {t}" for t in swot.get('threats', []))}
"""
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ê²½ìŸ í¬ì§€ì…˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

async def generate_industry_report(industry: str, report_type: str, include_rankings: bool) -> List[types.TextContent]:
    try:
        if not API_KEY:
            return [types.TextContent(type="text", text="âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_dart_api_keyë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")]
        industry_result = await benchmark_analyzer.generate_industry_report(industry, report_type)
        text = f"""# ğŸ­ {industry} ì—…ê³„ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š ì—…ê³„ ê°œìš”
- **ì—…ì¢…**: {industry}
- **ë¶„ì„ ê¸°ì—… ìˆ˜**: {industry_result.get('companies_analyzed', 0)}ê°œ
- **ë¦¬í¬íŠ¸ ìœ í˜•**: {report_type.title()}

## ğŸŒŸ ì—…ê³„ íŠ¹ì„±
{industry_result.get('industry_overview', {}).get('market_characteristics', 'N/A')}

## ğŸ” ì£¼ìš” íŠ¸ë Œë“œ
"""
        for trend in industry_result.get('industry_overview', {}).get('key_trends', []):
            text += f"- {trend}\n"
        if include_rankings:
            text += "\n## ğŸ“‹ ê¸°ì—… ìˆœìœ„ (ì£¼ìš” ì§€í‘œ ê¸°ì¤€)\n- ROE, ë§¤ì¶œì•¡ì¦ê°€ìœ¨ ë“± í•µì‹¬ ì§€í‘œ ì¢…í•© í‰ê°€\n"
        text += f"\n---\n*ë¦¬í¬íŠ¸ ìƒì„±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        return [types.TextContent(type="text", text=text)]
    except Exception as e:
        return [types.TextContent(type="text", text=f"âŒ ì—…ê³„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]

def _get_report_name(reprt_code: str) -> str:
    """ë³´ê³ ì„œ ì½”ë“œë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    code_names = {
        '11011': '1ë¶„ê¸°ë³´ê³ ì„œ',
        '11012': 'ë°˜ê¸°ë³´ê³ ì„œ', 
        '11013': '3ë¶„ê¸°ë³´ê³ ì„œ',
        '11014': 'ì‚¬ì—…ë³´ê³ ì„œ',
        '11001': 'ì •ê¸°ê³µì‹œ'
    }
    return code_names.get(reprt_code, f'ë³´ê³ ì„œ({reprt_code})')

# XBRL ë°±ì—… ë£¨í‹´ (ê²½ëŸ‰ êµ¬í˜„)
def _detect_report_rcept_no(corp_code: str, year: str) -> Optional[tuple[str, str]]:
    """í•´ë‹¹ ì—°ë„ì˜ ì‚¬ì—…/ê°ì‚¬ ë³´ê³ ì„œ ì ‘ìˆ˜ë²ˆí˜¸(rcept_no) íƒì§€ (Aâ†’F ìˆœ)"""
    try:
        base_params = {
            'crtfc_key': API_KEY,
            'corp_code': corp_code,
            'bgn_de': f"{year}0101",
            'end_de': f"{year}1231",
            'page_count': 100,
            'last_reprt_at': 'Y'
        }
        for src in ['A', 'F']:
            params = dict(base_params); params['pblntf_ty'] = src
            res = requests.get('https://opendart.fss.or.kr/api/list.json', params=params).json()
            if res.get('status') == '000':
                # ì‚¬ì—…/ê°ì‚¬ë³´ê³ ì„œ ìš°ì„ , ìµœì‹  ì ‘ìˆ˜ì¼ ìš°ì„ 
                items = sorted(res.get('list') or [], key=lambda x: x.get('rcept_dt', ''), reverse=True)
                for it in items:
                    rn = it.get('report_nm', '')
                    if ('ì‚¬ì—…ë³´ê³ ì„œ' in rn) or ('ê°ì‚¬ë³´ê³ ì„œ' in rn):
                        rno = it.get('rcept_no')
                        if rno:
                            return (rno, src)
    except Exception:
        pass
    return None

def _fetch_attachments(rcept_no: str) -> list[dict]:
    """ì ‘ìˆ˜ë²ˆí˜¸ì˜ ì²¨ë¶€ëª©ë¡(ë¬¸ì„œ/íŒŒì¼) ì¡°íšŒ.
    - OpenDART document.xmlì„ ìš°ì„  ì‹œë„í•˜ì—¬ ì²¨ë¶€ URLì„ ìˆ˜ì§‘
    - íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë°°ì—´ ë°˜í™˜
    """
    try:
        url = 'https://opendart.fss.or.kr/api/document.xml'
        resp = requests.get(url, params={'crtfc_key': API_KEY, 'rcept_no': rcept_no}, timeout=20)
        if resp.status_code != 200:
            return []
        xml_text = resp.content
        try:
            root = ET.fromstring(xml_text)
        except Exception:
            # ì‘ë‹µì´ XMLì´ ì•„ë‹ ìˆ˜ ìˆìŒ
            return []
        attachments: list[dict] = []
        # document.xml ìŠ¤í‚¤ë§ˆê°€ ê³µê°œ í¬ë§·ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆì–´, URL í˜•íƒœ í…ìŠ¤íŠ¸ë¥¼ ì „ìˆ˜ íƒìƒ‰
        for elem in root.iter():
            text = (elem.text or '').strip()
            if text.startswith('http') and any(ext in text.lower() for ext in ['.xbrl', '.xml', '.zip']):
                attachments.append({'url': text, 'name': elem.tag})
            # ì†ì„±ì—ë„ URLì´ ìˆì„ ìˆ˜ ìˆìŒ
            for k, v in (elem.attrib or {}).items():
                if isinstance(v, str) and v.startswith('http') and any(ext in v.lower() for ext in ['.xbrl', '.xml', '.zip']):
                    attachments.append({'url': v, 'name': f"{elem.tag}:{k}"})
        # ì¤‘ë³µ ì œê±°
        seen = set(); uniq = []
        for a in attachments:
            u = a['url']
            if u not in seen:
                seen.add(u); uniq.append(a)
        return uniq
    except Exception:
        return []

def _download_any_attachment(rcept_no: str, exts: list[str]) -> Optional[bytes]:
    """document.xmlì—ì„œ íŠ¹ì • í™•ì¥ì í›„ë³´ë¥¼ ìš°ì„  ë‹¤ìš´ë¡œë“œ."""
    try:
        candidates = _fetch_attachments(rcept_no)
        for att in candidates:
            u = att.get('url')
            if not u:
                continue
            if any(ext in u.lower() for ext in exts):
                try:
                    r = requests.get(u, timeout=25)
                    if r.status_code == 200 and r.content:
                        return r.content
                except Exception:
                    continue
    except Exception:
        return None
    return None

def _download_xbrl_stream(rcept_no: str) -> Optional[bytes]:
    """XBRL(ë˜ëŠ” zip) ì›ë¬¸ ë°”ì´íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ (ê°€ëŠ¥í•œ ê²½ìš°). ì‹¤íŒ¨ ì‹œ None."""
    data = _download_any_attachment(rcept_no, ['.xbrl', '.xml', '.zip'])
    if data:
        return data
    # ë°±ì—…: ì•Œë ¤ì§„ API ê²½ë¡œ ì‹œë„
    try:
        for url in [
            'https://opendart.fss.or.kr/api/xbrl.zip',
            'https://opendart.fss.or.kr/api/xbrl.xml'
        ]:
            resp = requests.get(url, params={'crtfc_key': API_KEY, 'rcept_no': rcept_no}, timeout=20)
            if resp.status_code == 200 and resp.content:
                return resp.content
    except Exception:
        pass
    return None

# PDF ë°±ì—…: ë‹¤ìš´ë¡œë“œ ë° í…Œì´ë¸” íŒŒì‹±(ê°„ë‹¨)
def _download_pdf_stream(rcept_no: str) -> Optional[bytes]:
    if not PDF_AVAILABLE:
        return None
    return _download_any_attachment(rcept_no, ['.pdf'])

def _parse_tables_from_pdf(pdf_bytes: bytes) -> list[pd.DataFrame]:
    if not PDF_AVAILABLE:
        return []
    try:
        import io as _io
        tables: list[pd.DataFrame] = []
        with pdfplumber.open(_io.BytesIO(pdf_bytes)) as pdf:
            for page in pdf.pages:
                try:
                    ts = page.extract_tables()
                    for t in ts or []:
                        if not t or len(t) < 2:
                            continue
                        df = pd.DataFrame(t[1:], columns=t[0])
                        tables.append(df)
                except Exception:
                    continue
        return tables
    except Exception:
        return []

def _pick_statement_table_from_pdf(tables: list[pd.DataFrame], statement_type: str) -> Optional[pd.DataFrame]:
    # ê°„ë‹¨ í‚¤ì›Œë“œ í•„í„°ë¡œ ì¬ë¬´ì œí‘œ í…Œì´ë¸” í›„ë³´ ì„ íƒ
    keys = {
        'í˜„ê¸ˆíë¦„í‘œ': ['í˜„ê¸ˆíë¦„', 'ì˜ì—…í™œë™', 'íˆ¬ìí™œë™', 'ì¬ë¬´í™œë™'],
        'ì†ìµê³„ì‚°ì„œ': ['ì†ìµ', 'ë§¤ì¶œ', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ'],
        'ì¬ë¬´ìƒíƒœí‘œ': ['ì¬ë¬´ìƒíƒœ', 'ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„'],
        'ìë³¸ë³€ë™í‘œ': ['ìë³¸ë³€ë™', 'ìë³¸ê¸ˆ', 'ì´ìµì‰ì—¬ê¸ˆ'],
    }.get(statement_type, [])
    for df in tables:
        text = ' '.join(map(str, df.columns)) + ' ' + ' '.join(df.astype(str).fillna('').values.flatten())
        if any(k in text for k in keys):
            return df
    return None

def _parse_cashflow_from_xbrl_bytes(content: bytes) -> Optional[pd.DataFrame]:
    """XBRL(XML/ZIP) ë‚´ìš©ì—ì„œ í˜„ê¸ˆíë¦„í‘œë¥¼ íŒŒì‹±. ì‹¤íŒ¨ ì‹œ None."""
    try:
        data = content
        # ZIPì´ë©´ ì••ì¶• í•´ì œ í›„ ì²« XML í›„ë³´ ì‚¬ìš©
        bio = io.BytesIO(data)
        if zipfile.is_zipfile(bio):
            with zipfile.ZipFile(bio) as zf:
                # XBRL íŒŒì¼ í›„ë³´
                xml_names = [n for n in zf.namelist() if n.lower().endswith(('.xml', '.xbrl'))]
                for name in xml_names:
                    try:
                        xml_bytes = zf.read(name)
                        df = _parse_cashflow_xml(xml_bytes)
                        if df is not None and not df.empty:
                            return df
                    except Exception:
                        continue
            return None
        # XML/XBRL ë°”ë¡œ íŒŒì‹±
        return _parse_cashflow_xml(data)
    except Exception:
        return None

_cashflow_patterns = [
    re.compile(r"ì˜ì—…í™œë™[^\n]*í˜„ê¸ˆíë¦„"),
    re.compile(r"íˆ¬ìí™œë™[^\n]*í˜„ê¸ˆíë¦„"),
    re.compile(r"ì¬ë¬´í™œë™[^\n]*í˜„ê¸ˆíë¦„"),
    re.compile(r"(?:í˜„ê¸ˆ[^\n]*?(?:ì¦ê°€|ê°ì†Œ|ì¦ê°))"),
]

def _parse_cashflow_xml(xml_bytes: bytes) -> Optional[pd.DataFrame]:
    """XBRL XMLì—ì„œ í˜„ê¸ˆíë¦„í‘œ í›„ë³´ ë…¸ë“œë¥¼ ì°¾ì•„ í‘œë¡œ ë³€í™˜."""
    try:
        # ë‹¨ìˆœ íŠ¸ë¦¬ íŒŒì‹± + í…ìŠ¤íŠ¸ ê¸°ë°˜ í›„ë³´ íƒìƒ‰(í™˜ê²½ ë…ë¦½ì  ê²½ëŸ‰ íŒŒì„œ)
        text = xml_bytes.decode('utf-8', errors='ignore')
        # í–‰ ë‹¨ìœ„ í›„ë³´ ì¶”ì¶œ
        lines = [l.strip() for l in text.splitlines() if l.strip()]
        rows = []
        for ln in lines:
            if any(p.search(ln) for p in _cashflow_patterns):
                # ê¸ˆì•¡ íŒ¨í„´ ì¶”ì¶œ(ìˆ«ì/ì½¤ë§ˆ/ê´„í˜¸)
                m = re.findall(r"([-\wê°€-í£\s\(\)]+)[\s:]+([\-\(\),0-9]+)(?:[\s,/]+([\-\(\),0-9]+))?(?:[\s,/]+([\-\(\),0-9]+))?", ln)
                for acc, th, fr, bf in m:
                    rows.append({'ê³„ì •': acc.strip(), 'ë‹¹ê¸°': th, 'ì „ê¸°': fr, 'ì „ì „ê¸°': bf})
        if rows:
            return pd.DataFrame(rows)
    except Exception:
        return None
    return None

def _try_fetch_cashflow_from_xbrl(rcept_no: str) -> Optional[pd.DataFrame]:
    """ì •ì‹ ì—”ë“œí¬ì¸íŠ¸ ê¸°ë°˜ìœ¼ë¡œ XBRLì—ì„œ í˜„ê¸ˆíë¦„í‘œ ì¶”ì¶œì„ ê°•í™”í•œ ë°±ì—… ë£¨í‹´."""
    _ = _fetch_attachments(rcept_no)
    content = _download_xbrl_stream(rcept_no)
    if not content:
        return None
    return _parse_cashflow_from_xbrl_bytes(content)

# ì¼ë°˜í™”ëœ XBRL íŒŒì‹± (ëª¨ë“  ì¬ë¬´ì œí‘œ ìœ í˜•)
_def_stmt_map = {
    'í˜„ê¸ˆíë¦„í‘œ': [r"ì˜ì—…í™œë™[^\n]*í˜„ê¸ˆíë¦„", r"íˆ¬ìí™œë™[^\n]*í˜„ê¸ˆíë¦„", r"ì¬ë¬´í™œë™[^\n]*í˜„ê¸ˆíë¦„", r"í˜„ê¸ˆ[^\n]*ì¦ê°€|ê°ì†Œ|ì¦ê°"],
    'ì†ìµê³„ì‚°ì„œ': [r"ë§¤ì¶œì•¡|ìˆ˜ìµ\(ë§¤ì¶œì•¡\)|ì˜ì—…ìˆ˜ìµ", r"ì˜ì—…ì´ìµ", r"ë²•ì¸ì„¸ë¹„ìš©ì°¨ê°ì „ìˆœì´ìµ", r"ë‹¹ê¸°ìˆœì´ìµ|ë‹¹ê¸°ìˆœì´ìµ\(ì†ì‹¤\)"],
    'ì¬ë¬´ìƒíƒœí‘œ': [r"ìì‚°ì´ê³„", r"ë¶€ì±„ì´ê³„", r"ìë³¸ì´ê³„", r"ìœ ë™ìì‚°", r"ìœ ë™ë¶€ì±„", r"í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°"],
    'ìë³¸ë³€ë™í‘œ': [r"ìë³¸ê¸ˆ", r"ê¸°íƒ€í¬ê´„ì†ìµëˆ„ê³„ì•¡", r"ì´ìµì‰ì—¬ê¸ˆ|ê²°ì†ê¸ˆ", r"ì§€ë°°ê¸°ì—…?ì†Œìœ ì£¼ì§€ë¶„", r"ë¹„ì§€ë°°ì§€ë¶„"],
}

def _get_statement_patterns(statement_type: str) -> list[re.Pattern]:
    pats = _def_stmt_map.get(statement_type, [])
    return [re.compile(p) for p in pats]

def _parse_statement_xml(xml_bytes: bytes, patterns: list[re.Pattern]) -> Optional[pd.DataFrame]:
    try:
        text = xml_bytes.decode('utf-8', errors='ignore')
        lines = [l.strip() for l in text.splitlines() if l.strip()]
        rows = []
        for ln in lines:
            if any(p.search(ln) for p in patterns):
                m = re.findall(r"([-\wê°€-í£\s\(\)]+)[\s:]+([\-\(\),0-9]+)(?:[\s,/]+([\-\(\),0-9]+))?(?:[\s,/]+([\-\(\),0-9]+))?", ln)
                for acc, th, fr, bf in m:
                    rows.append({'ê³„ì •': acc.strip(), 'ë‹¹ê¸°': th, 'ì „ê¸°': fr, 'ì „ì „ê¸°': bf})
        if rows:
            return pd.DataFrame(rows)
    except Exception:
        return None
    return None

def _parse_statement_from_xbrl_bytes(content: bytes, statement_type: str) -> Optional[pd.DataFrame]:
    try:
        pats = _get_statement_patterns(statement_type)
        if not pats:
            return None
        bio = io.BytesIO(content)
        if zipfile.is_zipfile(bio):
            with zipfile.ZipFile(bio) as zf:
                xml_names = [n for n in zf.namelist() if n.lower().endswith(('.xml', '.xbrl'))]
                for name in xml_names:
                    try:
                        xml_bytes = zf.read(name)
                        df = _parse_statement_xml(xml_bytes, pats)
                        if df is not None and not df.empty:
                            return df
                    except Exception:
                        continue
            return None
        return _parse_statement_xml(content, pats)
    except Exception:
        return None

def _try_fetch_statement_from_xbrl(rcept_no: str, statement_type: str) -> Optional[pd.DataFrame]:
    _ = _fetch_attachments(rcept_no)
    content = _download_xbrl_stream(rcept_no)
    if not content:
        return None
    return _parse_statement_from_xbrl_bytes(content, statement_type)

@app.list_tools()
async def handle_list_tools() -> list[Tool]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤"""
    return [
        Tool(
            name="set_dart_api_key",
            description="DART API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "api_key": {
                        "type": "string",
                        "description": "DART API í‚¤"
                    }
                },
                "required": ["api_key"]
            }
        ),
        Tool(
            name="get_company_info",
            description="ê¸°ì—…ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "corp_code": {"type": "string", "description": "ê¸°ì—… ê³ ìœ ë²ˆí˜¸ (ì„ íƒ: ì§€ì • ì‹œ íšŒì‚¬ëª… ê²€ìƒ‰ ìƒëµ)"}
                }
            }
        ),
        Tool(
            name="get_financial_statements",
            description="ê¸°ì—…ì˜ ì¬ë¬´ì œí‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {
                        "type": "string",
                        "description": "íšŒì‚¬ëª…"
                    },
                    "bsns_year": {
                        "type": "string",
                        "description": "ì‚¬ì—…ì—°ë„ (ì˜ˆ: 2024)",
                        "default": "2024"
                    },
                    "reprt_code": {
                        "type": "string",
                        "description": "ë³´ê³ ì„œ ì½”ë“œ (11011: 1ë¶„ê¸°, 11012: ë°˜ê¸°, 11013: 3ë¶„ê¸°, 11014: ì‚¬ì—…ë³´ê³ ì„œ)",
                        "default": "11014"
                    },
                    "fs_div": {
                        "type": "string",
                        "description": "ì¬ë¬´ì œí‘œ êµ¬ë¶„ (CFS: ì—°ê²°, OFS: ë³„ë„)",
                        "default": "CFS"
                    },
                    "statement_type": {
                        "type": "string",
                        "description": "ì¬ë¬´ì œí‘œ ì¢…ë¥˜ (ì¬ë¬´ìƒíƒœí‘œ, ì†ìµê³„ì‚°ì„œ, í˜„ê¸ˆíë¦„í‘œ, ìë³¸ë³€ë™í‘œ)",
                        "default": "ì†ìµê³„ì‚°ì„œ"
                    },
                    "corp_code": {"type": "string", "description": "ê¸°ì—… ê³ ìœ ë²ˆí˜¸ (ì„ íƒ)"}
                }
            }
        ),
        Tool(
            name="get_financial_ratios",
            description="ì£¼ìš” ì¬ë¬´ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "bsns_year": {"type": "string", "description": "ì‚¬ì—…ì—°ë„ (ì˜ˆ: 2024)", "default": "2024"},
                    "ratio_categories": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["profitability", "stability", "activity", "growth"]},
                        "default": ["profitability", "stability"]
                    },
                    "include_industry_avg": {"type": "boolean", "default": True},
                    "corp_code": {"type": "string", "description": "ê¸°ì—… ê³ ìœ ë²ˆí˜¸ (ì„ íƒ)"}
                }
            }
        ),
        Tool(
            name="analyze_time_series",
            description="ê¸°ì—…ì˜ ì¬ë¬´ ì„±ê³¼ ì‹œê³„ì—´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string"},
                    "analysis_period": {"type": "integer", "default": 5},
                    "metrics": {"type": "array", "items": {"type": "string"}, "default": ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]},
                    "forecast_periods": {"type": "integer", "default": 8}
                },
                "required": ["corp_name"]
            }
        ),
        Tool(
            name="compare_with_industry",
            description="ê¸°ì—…ì„ ë™ì¢… ì—…ê³„ì™€ ë²¤ì¹˜ë§ˆí¬ ë¹„êµí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string"},
                    "industry": {"type": "string", "enum": ["ë°˜ë„ì²´", "ì „ê¸°ì „ì", "í™”í•™", "ìë™ì°¨", "ê¸ˆìœµ", "ì¸í„°ë„·"]},
                    "comparison_metrics": {"type": "array", "items": {"type": "string"}, "default": ["ROE", "ROA", "ë¶€ì±„ë¹„ìœ¨"]},
                    "analysis_type": {"type": "string", "enum": ["basic", "detailed"], "default": "basic"}
                },
                "required": ["corp_name", "industry"]
            }
        ),
        Tool(
            name="get_disclosure_list",
            description="ê¸°ì—…ì˜ ê³µì‹œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "bgn_de": {"type": "string", "description": "ê²€ìƒ‰ ì‹œì‘ì¼ (YYYYMMDD)"},
                    "end_de": {"type": "string", "description": "ê²€ìƒ‰ ì¢…ë£Œì¼ (YYYYMMDD)"},
                    "page_count": {"type": "integer", "description": "í˜ì´ì§€ ë‹¹ ë°ì´í„° ìˆ˜", "default": 10}
                },
                "required": ["corp_name", "bgn_de", "end_de"]
            }
        ),
        Tool(
            name="compare_financials",
            description="ì—¬ëŸ¬ ê¸°ì—…ì˜ ì¬ë¬´ì§€í‘œë¥¼ ë¹„êµí•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "companies": {"type": "array", "items": {"type": "string"}, "description": "ë¹„êµí•  ê¸°ì—… ëª©ë¡"},
                    "corp_codes": {"type": "array", "items": {"type": "string"}, "description": "ê¸°ì—… ê³ ìœ ë²ˆí˜¸ ëª©ë¡(ì„ íƒ, companiesì™€ ë™ì¼ ìˆœì„œ)"},
                    "bsns_year": {"type": "string", "description": "ë¹„êµí•  ì—°ë„ (ì˜ˆ: 2024)", "default": "2024"},
                    "comparison_metrics": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ", "ROE", "ë¶€ì±„ë¹„ìœ¨", "ì˜ì—…ì´ìµë¥ "]},
                        "default": ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]
                    },
                    "visualization": {"type": "boolean", "default": True, "description": "ì°¨íŠ¸ ì‹œê°í™” í¬í•¨ ì—¬ë¶€"}
                },
                "required": ["companies", "bsns_year"]
            }
        ),
        Tool(
            name="get_company_news",
            description="ê¸°ì—…ì˜ ìµœê·¼ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "search_period": {"type": "string", "description": "ê²€ìƒ‰í•  ê¸°ê°„ (day/1ì¼, week/1ì£¼ì¼, month/1ê°œì›”)", "default": "week"}
                },
                "required": ["corp_name", "search_period"]
            }
        ),
        Tool(
            name="analyze_news_sentiment",
            description="ê¸°ì—… ë‰´ìŠ¤ì˜ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "search_period": {"type": "string", "description": "ë¶„ì„í•  ê¸°ê°„ (day/1ì¼, week/1ì£¼ì¼, month/1ê°œì›”)", "default": "week"},
                    "analysis_depth": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¶„ì„ ê¹Šì´"}
                },
                "required": ["corp_name", "search_period"]
            }
        ),
        Tool(
            name="detect_financial_events",
            description="ê¸°ì—…ì˜ ì¬ë¬´ ì´ë²¤íŠ¸ë¥¼ íƒì§€í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "monitoring_period": {"type": "integer", "default": 30, "description": "ëª¨ë‹ˆí„°ë§ ê¸°ê°„ (ì¼)"},
                    "event_types": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["ì „ì²´", "ì‹ ê·œ ê³µì‹œ", "ì‹ ê·œ ì¬ë¬´ì œí‘œ", "ì‹ ê·œ ì†ìµê³„ì‚°ì„œ", "ì‹ ê·œ ì¬ë¬´ìƒíƒœí‘œ", "ì‹ ê·œ í˜„ê¸ˆíë¦„í‘œ", "ì‹ ê·œ ìë³¸ë³€ë™í‘œ", "ê¸°íƒ€"]},
                        "default": ["ì „ì²´"]
                    }
                },
                "required": ["corp_name", "monitoring_period"]
            }
        ),
        Tool(
            name="generate_investment_signal",
            description="ê¸°ì—…ì˜ íˆ¬ì ì‹ í˜¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "analysis_period": {"type": "integer", "default": 5, "description": "ë¶„ì„ ê¸°ê°„ (ë…„)"},
                    "weight_config": {
                        "type": "object",
                        "properties": {
                            "news_sentiment": {"type": "number", "default": 0.5, "description": "ë‰´ìŠ¤ ê°ì„± ê°€ì¤‘ì¹˜"},
                            "market_events": {"type": "number", "default": 0.3, "description": "ì¬ë¬´ ì´ë²¤íŠ¸ ê°€ì¤‘ì¹˜"},
                            "financial_ratios": {"type": "number", "default": 0.2, "description": "ì¬ë¬´ë¹„ìœ¨ ê°€ì¤‘ì¹˜"}
                        },
                        "required": ["news_sentiment", "market_events", "financial_ratios"]
                    },
                    "risk_tolerance": {"type": "string", "enum": ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"], "default": "ë³´í†µ", "description": "ë¦¬ìŠ¤í¬ í—ˆìš©ë„"}
                },
                "required": ["corp_name", "analysis_period", "weight_config", "risk_tolerance"]
            }
        ),
        Tool(
            name="generate_summary_report",
            description="ê¸°ì—…ì˜ ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "report_type": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¦¬í¬íŠ¸ ìœ í˜•"},
                    "include_charts": {"type": "boolean", "default": True, "description": "ì°¨íŠ¸ í¬í•¨ ì—¬ë¶€"},
                    "analysis_depth": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¶„ì„ ê¹Šì´"}
                },
                "required": ["corp_name", "report_type"]
            }
        ),
        Tool(
            name="export_to_pdf",
            description="ë¦¬í¬íŠ¸ ë‚´ìš©ì„ PDFë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "report_content": {"type": "string", "description": "ë¦¬í¬íŠ¸ ë‚´ìš©"},
                    "include_metadata": {"type": "boolean", "default": True, "description": "ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€"},
                    "page_format": {"type": "string", "enum": ["A4", "Letter"], "default": "A4", "description": "í˜ì´ì§€ í˜•ì‹"}
                },
                "required": ["corp_name", "report_content"]
            }
        ),
        Tool(
            name="optimize_portfolio",
            description="í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "companies": {"type": "array", "items": {"type": "string"}, "description": "í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ê¸°ì—… ëª©ë¡"},
                    "investment_amount": {"type": "integer", "default": 100000000, "description": "ì´ íˆ¬ìê¸ˆì•¡ (ì›)"},
                    "risk_tolerance": {"type": "string", "enum": ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"], "default": "ë³´í†µ", "description": "ë¦¬ìŠ¤í¬ í—ˆìš©ë„"},
                    "optimization_method": {"type": "string", "enum": ["ìµœëŒ€ ìˆ˜ìµ", "ìµœì†Œ ë¦¬ìŠ¤í¬", "ê· í˜•"], "default": "ê· í˜•", "description": "ìµœì í™” ë°©ë²•"}
                },
                "required": ["companies", "investment_amount", "risk_tolerance", "optimization_method"]
            }
        ),
        Tool(
            name="analyze_competitive_position",
            description="ê¸°ì—…ì˜ ê²½ìŸ í¬ì§€ì…˜ì„ ë¶„ì„í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "corp_name": {"type": "string", "description": "íšŒì‚¬ëª…"},
                    "competitors": {"type": "array", "items": {"type": "string"}, "description": "ê²½ìŸì‚¬ ëª©ë¡"},
                    "analysis_metrics": {
                        "type": "array",
                        "items": {"type": "string", "enum": ["SWOT", "ì¬ë¬´ë¹„ìœ¨", "ì‹œì¥ ì ìœ ìœ¨", "ì„±ì¥ì„±", "ìœ„í—˜ì„±"]},
                        "default": ["SWOT", "ì¬ë¬´ë¹„ìœ¨"]
                    },
                    "include_swot": {"type": "boolean", "default": True, "description": "SWOT ë¶„ì„ í¬í•¨ ì—¬ë¶€"}
                },
                "required": ["corp_name", "competitors"]
            }
        ),
        Tool(
            name="generate_industry_report",
            description="íŠ¹ì • ì—…ê³„ì˜ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤",
            inputSchema={
                "type": "object",
                "properties": {
                    "industry": {"type": "string", "description": "ì—…ê³„ëª… (ì˜ˆ: ë°˜ë„ì²´, ì „ê¸°ì „ì, í™”í•™, ìë™ì°¨, ê¸ˆìœµ, ì¸í„°ë„·)"},
                    "report_type": {"type": "string", "enum": ["basic", "detailed"], "default": "basic", "description": "ë¦¬í¬íŠ¸ ìœ í˜•"},
                    "include_rankings": {"type": "boolean", "default": True, "description": "ê¸°ì—… ìˆœìœ„ í¬í•¨ ì—¬ë¶€"}
                },
                "required": ["industry", "report_type"]
            }
        )
    ]

@app.call_tool()
async def handle_call_tool(name: str, arguments: dict) -> list[types.TextContent]:
    """ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤"""
    if name == "set_dart_api_key":
        return await set_dart_api_key(arguments["api_key"])
    elif name == "get_company_info":
        return await get_company_info(arguments.get("corp_name"), arguments.get("corp_code"))
    elif name == "get_financial_statements":
        return await get_financial_statements(
            arguments.get("corp_name"),
            arguments.get("bsns_year", "2024"),
            arguments.get("reprt_code", "11014"),
            arguments.get("fs_div", "CFS"),
            arguments.get("statement_type", "ì†ìµê³„ì‚°ì„œ"),
            arguments.get("corp_code")
        )
    elif name == "get_financial_ratios":
        return await get_financial_ratios(
            arguments.get("corp_name"),
            arguments["bsns_year"],
            arguments.get("ratio_categories", ["profitability", "stability"]),
            arguments.get("include_industry_avg", True),
            arguments.get("corp_code")
        )
    elif name == "analyze_time_series":
        return await analyze_time_series(
            arguments["corp_name"],
            arguments.get("analysis_period", 5),
            arguments.get("metrics", ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]),
            arguments.get("forecast_periods", 8)
        )
    elif name == "compare_with_industry":
        return await compare_with_industry(
            arguments["corp_name"],
            arguments["industry"],
            arguments.get("comparison_metrics", ["ROE", "ROA", "ë¶€ì±„ë¹„ìœ¨"]),
            arguments.get("analysis_type", "basic")
        )
    elif name == "get_disclosure_list":
        return await get_disclosure_list(
            arguments.get("corp_name"),
            arguments["bgn_de"],
            arguments["end_de"],
            arguments.get("page_count", 10),
            arguments.get("corp_code")
        )
    elif name == "compare_financials":
        return await compare_financials(
            arguments["companies"],
            arguments["bsns_year"],
            arguments.get("comparison_metrics", ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ"]),
            arguments.get("visualization", True),
            arguments.get("corp_codes")
        )
    elif name == "get_company_news":
        return await get_company_news(
            arguments["corp_name"],
            arguments["search_period"],
            arguments.get("news_categories", ["ì „ì²´"]),
            arguments.get("include_sentiment", True)
        )
    elif name == "analyze_news_sentiment":
        return await analyze_news_sentiment(
            arguments["corp_name"],
            arguments["search_period"],
            arguments.get("analysis_depth", "basic")
        )
    elif name == "detect_financial_events":
        return await detect_financial_events(
            arguments["corp_name"],
            arguments["monitoring_period"],
            arguments.get("event_types", ["ì „ì²´"])
        )
    elif name == "generate_investment_signal":
        return await generate_investment_signal(
            arguments["corp_name"],
            arguments["analysis_period"],
            arguments["weight_config"],
            arguments["risk_tolerance"]
        )
    elif name == "generate_summary_report":
        return await generate_summary_report(
            arguments["corp_name"],
            arguments["report_type"],
            arguments.get("include_charts", True),
            arguments.get("analysis_depth", "basic")
        )
    elif name == "export_to_pdf":
        return await export_to_pdf(
            arguments["corp_name"],
            arguments["report_content"],
            arguments.get("include_metadata", True),
            arguments.get("page_format", "A4")
        )
    elif name == "optimize_portfolio":
        return await optimize_portfolio(
            arguments["companies"],
            arguments["investment_amount"],
            arguments["risk_tolerance"],
            arguments["optimization_method"]
        )
    elif name == "analyze_competitive_position":
        return await analyze_competitive_position(
            arguments["corp_name"],
            arguments["competitors"],
            arguments.get("analysis_metrics", ["SWOT", "ì¬ë¬´ë¹„ìœ¨"]),
            arguments.get("include_swot", True)
        )
    elif name == "generate_industry_report":
        return await generate_industry_report(
            arguments["industry"],
            arguments["report_type"],
            arguments.get("include_rankings", True)
        )
    else:
        return [types.TextContent(type="text", text=f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}")]

async def main():
    """MCP ì„œë²„ ë©”ì¸ í•¨ìˆ˜"""
    # stdio_serverë¥¼ ì‚¬ìš©í•˜ì—¬ MCP ì„œë²„ ì‹¤í–‰
    async with stdio_server() as (read_stream, write_stream):
        await app.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="OpenCorpInsight",
                server_version="1.0.0",
                capabilities=app.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )

if __name__ == "__main__":
    asyncio.run(main()) 